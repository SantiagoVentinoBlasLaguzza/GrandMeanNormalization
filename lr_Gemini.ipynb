{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkt9SMOwT2l9",
        "outputId": "57122c68-33d4-4cb8-f0d2-894d5b1c1081"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# prompt: import drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ─────────────────────────────────────────\n",
        "# test_multiple_classifiers_fast.py\n",
        "# ─────────────────────────────────────────\n",
        "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
        "from sklearn.model_selection import HalvingGridSearchCV, RandomizedSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "import pandas as pd, numpy as np, json, os, time\n",
        "import wandb\n",
        "\n",
        "\n",
        "def fast_search_clf(X_tr, y_tr, X_val, y_val,\n",
        "                    X_te, y_te, project_dir, fold, *,\n",
        "                    seed=42, use_wandb=True, wb_group=\"clf_search\"):\n",
        "\n",
        "    import os, json, time\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    import wandb\n",
        "    from sklearn.pipeline import Pipeline\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    from sklearn.model_selection import StratifiedKFold, HalvingGridSearchCV, RandomizedSearchCV\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    from sklearn.svm import SVC\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, precision_recall_curve\n",
        "    import joblib\n",
        "\n",
        "    # ─── W&B run ─────────────────────────────────────────────\n",
        "    if use_wandb:\n",
        "        wandb_run = wandb.init(\n",
        "            project=\"VAE_ADCN\",\n",
        "            group=wb_group,\n",
        "            job_type=f\"fold_{fold}\",\n",
        "            config={\"fold\": fold, \"seed\": seed},\n",
        "            reinit=True\n",
        "        )\n",
        "    else:\n",
        "        wandb_run = None\n",
        "    # ─────────────────────────────────────────────────────────\n",
        "\n",
        "    inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=seed)\n",
        "\n",
        "    SEARCHERS = {\n",
        "        \"LogReg\": HalvingGridSearchCV(\n",
        "            Pipeline([\n",
        "                (\"scaler\", StandardScaler()),\n",
        "                (\"clf\", LogisticRegression(solver=\"saga\", max_iter=4000, random_state=seed))\n",
        "            ]),\n",
        "            param_grid={\n",
        "                \"clf__penalty\": [\"l1\", \"l2\"],\n",
        "                \"clf__C\": np.logspace(-3, 3, 5)\n",
        "            },\n",
        "            scoring=\"roc_auc\", cv=inner_cv,\n",
        "            factor=2, n_jobs=-1, verbose=0, random_state=seed\n",
        "        ),\n",
        "\n",
        "        \"SVM\": HalvingGridSearchCV(\n",
        "            Pipeline([\n",
        "                (\"scaler\", StandardScaler()),\n",
        "                (\"clf\", SVC(probability=True, random_state=seed))\n",
        "            ]),\n",
        "            param_grid={\n",
        "                \"clf__kernel\": [\"rbf\"],\n",
        "                \"clf__C\": np.logspace(-2, 2, 4),\n",
        "                \"clf__gamma\": np.logspace(-4, 0, 5)\n",
        "            },\n",
        "            scoring=\"roc_auc\", cv=inner_cv,\n",
        "            factor=2, n_jobs=-1, verbose=0, random_state=seed\n",
        "        ),\n",
        "\n",
        "        \"RF\": RandomizedSearchCV(\n",
        "            RandomForestClassifier(n_jobs=-1, random_state=seed, class_weight=\"balanced\"),\n",
        "            param_distributions={\n",
        "                \"n_estimators\": [100, 200, 400, 800],\n",
        "                \"max_depth\": [None, 10, 20],\n",
        "                \"min_samples_leaf\": [1, 2, 4]\n",
        "            },\n",
        "            n_iter=10, scoring=\"roc_auc\", cv=inner_cv,\n",
        "            n_jobs=-1, random_state=seed\n",
        "        )\n",
        "    }\n",
        "\n",
        "    results = []\n",
        "    for name, searcher in SEARCHERS.items():\n",
        "        t0 = time.time()\n",
        "        searcher.fit(X_tr, y_tr)\n",
        "        best = searcher.best_estimator_\n",
        "        elapsed = time.time() - t0\n",
        "\n",
        "        # ─────────── Validación (igual que antes) ───────────\n",
        "        p_val = best.predict_proba(X_val)[:, 1]\n",
        "        thr   = max(np.arange(0.05, 0.95, 0.05),\n",
        "                    key=lambda t: accuracy_score(y_val, p_val >= t))\n",
        "\n",
        "        # ─────────── Test ───────────\n",
        "        p_te = best.predict_proba(X_te)[:, 1]        # prob. de clase AD\n",
        "        probas_2d = np.column_stack([1 - p_te, p_te])  # ⬅️ NUEVO  (N,2)\n",
        "\n",
        "        y_pred = (p_te >= thr).astype(int)\n",
        "        acc = accuracy_score(y_te, y_pred)\n",
        "        auc = roc_auc_score(y_te, p_te)\n",
        "\n",
        "        # ─────────── Logging en W&B ───────────\n",
        "        if wandb_run:\n",
        "            wandb_run.log({\n",
        "                \"clf\": name,\n",
        "                \"best_auc_val\": searcher.best_score_,\n",
        "                \"thr\": thr,\n",
        "                \"acc_test\": acc,\n",
        "                \"auc_test\": auc,\n",
        "                \"time_s\": elapsed,\n",
        "                **{f\"hp_{k}\": v for k, v in searcher.best_params_.items()},\n",
        "                # Curvas usando la matriz 2-D\n",
        "                f\"roc_curve_{name}\": wandb.plot.roc_curve(\n",
        "                    y_true=y_te,\n",
        "                    y_probas=probas_2d,\n",
        "                    labels=[\"CN\", \"AD\"],\n",
        "                    title=f\"ROC {name} (fold {fold})\"\n",
        "                ),\n",
        "                f\"pr_curve_{name}\": wandb.plot.pr_curve(\n",
        "                    y_true=y_te,\n",
        "                    y_probas=probas_2d,\n",
        "                    labels=[\"CN\", \"AD\"],\n",
        "                    title=f\"PR {name} (fold {fold})\"\n",
        "                )\n",
        "            })\n",
        "\n",
        "\n",
        "        print(f\"{name:>8}: AUC_val={searcher.best_score_:.3f} | \"\n",
        "              f\"AUC_te={auc:.3f} | ACC_te={acc:.3f} | thr={thr:.2f} \"\n",
        "              f\"(⏱ {elapsed:.1f}s)\")\n",
        "\n",
        "        # Guardar modelo si querés\n",
        "        model_path = os.path.join(project_dir, f\"fold_{fold}_best_{name}.pkl\")\n",
        "        joblib.dump(best, model_path)\n",
        "\n",
        "        results.append(dict(\n",
        "            Classifier=name,\n",
        "            Best_Params=json.dumps(searcher.best_params_),\n",
        "            Threshold=thr,\n",
        "            Test_ACC=acc,\n",
        "            Test_AUC=auc,\n",
        "            Seconds=elapsed,\n",
        "            Model_File=model_path\n",
        "        ))\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "\n",
        "    csv_path = os.path.join(project_dir, f\"fold_{fold}_clf_results_fast.csv\")\n",
        "    df.to_csv(csv_path, index=False)\n",
        "    print(f\"Resultados → {csv_path}\")\n",
        "\n",
        "    if wandb_run:\n",
        "        wandb_run.save(csv_path)\n",
        "        wandb_run.finish()\n",
        "\n",
        "    return df\n",
        "\n"
      ],
      "metadata": {
        "id": "AQEDJeAS_vAb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "\"\"\"\n",
        "Trains a Beta-VAE on connectivity tensors (all subjects),\n",
        "then trains a classifier on the latent representations of AD vs CN subjects,\n",
        "and computes saliency maps to assess channel importance for AD/CN classification.\n",
        "\n",
        "Assumes preprocess.ipynb has been run and fold directories exist.\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader, Subset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import logging\n",
        "import json\n",
        "from torch import autocast\n",
        "from torch.amp import GradScaler\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "\n",
        "\n",
        "# --- Configuration ---\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(message)s\")\n",
        "\n",
        "# Adapt these paths and parameters as needed\n",
        "PROJECT_DIR = '/content/drive/MyDrive/GrandMeanNorm/' # Or '/home/diego/Escritorio/GrandMeanNorm/'\n",
        "FOLD_NUMBER = 1  # Which fold's data to use\n",
        "SEED = 42\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "# VAE Hyperparameters\n",
        "VAE_LEARNING_RATE = 1e-3\n",
        "VAE_EPOCHS = 8500 # Adjust as needed\n",
        "VAE_BATCH_SIZE = 64\n",
        "#LATENT_DIM = 256   # Dimension of the latent space\n",
        "LATENT_DIM = 256          #  ← esto era solo μ\n",
        "LATENT_DIM_CAT = LATENT_DIM * 2   # μ + σ\n",
        "BETA = 100          # Beta parameter for Beta-VAE (Beta=1 is standard VAE)\n",
        "INPUT_CHANNELS = 4 # Correlation, MI, Granger, DCV\n",
        "\n",
        "# Classifier Hyperparameters\n",
        "CLASSIFIER_LEARNING_RATE = 1e-4\n",
        "CLASSIFIER_EPOCHS = 300 # Adjust as needed\n",
        "CLASSIFIER_BATCH_SIZE = 32\n",
        "\n",
        "# Saliency Parameters\n",
        "N_SALIENCY_SAMPLES = 50 # Number of samples to average saliency over\n",
        "\n",
        "# Set Seed\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "# --- Data Loading ---\n",
        "\n",
        "def load_fold_data(project_dir, fold_num):\n",
        "    \"\"\"Loads preprocessed data for a specific fold.\"\"\"\n",
        "    fold_dir = os.path.join(project_dir, f\"fold_{fold_num}\")\n",
        "    if not os.path.exists(fold_dir):\n",
        "        raise FileNotFoundError(f\"Fold directory not found: {fold_dir}\")\n",
        "\n",
        "    print(f\"Loading data from {fold_dir}\")\n",
        "    try:\n",
        "        # Use the Z-scored data as input\n",
        "        train_z = torch.load(os.path.join(fold_dir, 'train_z.pt'), map_location='cpu', weights_only=False) # Set weights_only=False\n",
        "        val_z   = torch.load(os.path.join(fold_dir, 'val_z.pt'), map_location='cpu', weights_only=False) # Set weights_only=False\n",
        "        test_z  = torch.load(os.path.join(fold_dir, 'test_z.pt'), map_location='cpu', weights_only=False) # Set weights_only=False\n",
        "\n",
        "        train_labels = torch.load(os.path.join(fold_dir, 'train_labels.pt'), map_location='cpu', weights_only=False) # Set weights_only=False\n",
        "        val_labels   = torch.load(os.path.join(fold_dir, 'val_labels.pt'), map_location='cpu', weights_only=False) # Set weights_only=False\n",
        "        test_labels  = torch.load(os.path.join(fold_dir, 'test_labels.pt'), map_location='cpu', weights_only=False) # Set weights_only=False\n",
        "\n",
        "        # Combine train and val for VAE training if desired, or just use train\n",
        "        #all_train_data = torch.cat((train_z, val_z), dim=0)\n",
        "        #all_train_labels = np.concatenate((train_labels, val_labels), axis=0)\n",
        "\n",
        "        print(f\"Train data shape: {train_z.shape}\")\n",
        "        print(f\"Validation data shape: {val_z.shape}\")\n",
        "        print(f\"Test data shape: {test_z.shape}\")\n",
        "\n",
        "        return train_z, val_z, test_z, train_labels, val_labels, test_labels\n",
        "\n",
        "    except FileNotFoundError as e:\n",
        "        logging.error(f\"Error loading file: {e}\")\n",
        "        raise\n",
        "    except Exception as e:\n",
        "        logging.error(f\"An unexpected error occurred during data loading: {e}\")\n",
        "        raise\n",
        "\n",
        "# --- Beta-VAE Model ---\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_channels, latent_dim):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=4, stride=2, padding=0)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=0)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=0)\n",
        "\n",
        "        self.fc_1 = nn.Linear(128 * 19 * 19, 256*10)  # ✅ correcto\n",
        "        self.fc_2 = nn.Linear(256*10, 256*4)    # ❌ incorrecto\n",
        "        self.fc_mu = nn.Linear(256*4, latent_dim)\n",
        "        self.fc_logvar = nn.Linear(256*4, latent_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = x.flatten(1)\n",
        "        x = F.relu(self.fc_1(x))\n",
        "        x = F.relu(self.fc_2(x))\n",
        "        mu = self.fc_mu(x)\n",
        "        logvar = self.fc_logvar(x)\n",
        "        return mu, logvar\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_dim, output_channels):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(latent_dim, 256*4)\n",
        "        self.fc3 = nn.Linear(256*4,256*10)\n",
        "        self.fc2 = nn.Linear(256*10, 128 * 19 * 19)\n",
        "\n",
        "        self.deconv1 = nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=0, output_padding=0)\n",
        "        self.deconv2 = nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=0, output_padding=0)\n",
        "        self.deconv3 = nn.ConvTranspose2d(32, output_channels, kernel_size=4, stride=2, padding=0, output_padding=0)\n",
        "\n",
        "    def forward(self, z):\n",
        "        x = F.relu(self.fc1(z))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = x.view(-1, 128, 19, 19)\n",
        "        x = F.relu(self.deconv1(x))\n",
        "        x = F.relu(self.deconv2(x))\n",
        "        #x = torch.sigmoid(self.deconv3(x))\n",
        "        x = self.deconv3(x)  # No torch.sigmoid\n",
        "        return x\n",
        "\n",
        "\n",
        "class BetaVAE(nn.Module):\n",
        "    def __init__(self, input_channels, latent_dim, h, w):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(input_channels, latent_dim)\n",
        "        self.decoder = Decoder(latent_dim, input_channels)\n",
        "\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encoder(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decoder(z), mu, logvar\n",
        "\n",
        "def vae_loss_function(recon_x, x, mu, logvar, beta):\n",
        "    # Use MSE for reconstruction loss as input is Z-scored\n",
        "    BCE = F.mse_loss(recon_x, x, reduction='sum') / x.shape[0] # Per sample MSE\n",
        "\n",
        "    # KL divergence: 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
        "    # log(sigma^2) = log(exp(logvar)) = logvar\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) / x.shape[0] # Per sample KLD\n",
        "\n",
        "    return BCE + beta * KLD, BCE, KLD\n",
        "\n",
        "\n",
        "\n",
        "# --- Classifier Model ---\n",
        "class LatentClassifier(nn.Module):\n",
        "    def __init__(self, latent_dim, num_classes=1, dropout_p=0.1): # Add dropout_p\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(latent_dim, 64*2)\n",
        "        self.dropout1 = nn.Dropout(dropout_p) # Add dropout layer\n",
        "        self.fc2 = nn.Linear(64*2, 32*2)\n",
        "        self.dropout2 = nn.Dropout(dropout_p) # Add dropout layer\n",
        "        self.fc3 = nn.Linear(32*2, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout1(x) # Apply dropout\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout2(x) # Apply dropout\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# --- Training Functions ---\n",
        "\n",
        "def beta_schedule(ep, total_ep, β_max=50, ramp_frac=0.3):\n",
        "    ramp = int(total_ep * ramp_frac)\n",
        "    if ep < ramp:\n",
        "        return β_max * (ep / ramp)        # lineal\n",
        "    return β_max\n",
        "\n",
        "\n",
        "\n",
        "def train_vae(model, dataloader, optimizer, beta, device, scaler, epoch):\n",
        "    model.train()\n",
        "    total_loss, total_bce, total_kld = 0, 0, 0\n",
        "    for batch in dataloader:\n",
        "        data = batch[0].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        with autocast(device_type=\"cuda\", dtype=torch.float16):\n",
        "            recon_batch, mu, logvar = model(data)\n",
        "            beta_value = beta_schedule(epoch, VAE_EPOCHS, β_max=BETA)#cyclic_beta_schedule(epoch, total_epochs=VAE_EPOCHS, max_beta=BETA)\n",
        "            loss, bce, kld = vae_loss_function(recon_batch, data, mu, logvar, beta_value)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_bce += bce.item()\n",
        "        total_kld += kld.item()\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    avg_bce = total_bce / len(dataloader)\n",
        "    avg_kld = total_kld / len(dataloader)\n",
        "    return avg_loss, avg_bce, avg_kld\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_vae(model, dataloader, beta, device):\n",
        "    model.eval()\n",
        "    total_loss, total_bce, total_kld = 0, 0, 0\n",
        "    for batch, in dataloader:           # (solo tensores)\n",
        "        x = batch.to(device)\n",
        "        recon, mu, logvar = model(x)\n",
        "        loss, bce, kld = vae_loss_function(recon, x, mu, logvar, beta)\n",
        "        total_loss += loss.item()\n",
        "        total_bce  += bce.item()\n",
        "        total_kld  += kld.item()\n",
        "    n = len(dataloader)\n",
        "    return total_loss/n, total_bce/n, total_kld/n\n",
        "\n",
        "\n",
        "\n",
        "def train_classifier(classifier, vae_encoder, dataloader, optimizer, criterion, device, scaler):\n",
        "    classifier.train()\n",
        "    vae_encoder.eval()\n",
        "    total_loss, all_preds, all_labels = 0, [], []\n",
        "\n",
        "    for batch in dataloader:\n",
        "        data = batch[0].to(device)\n",
        "        labels = batch[1].float().unsqueeze(1).to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        with torch.no_grad():\n",
        "            mu, logvar = vae_encoder(data)\n",
        "            sigma = torch.exp(0.5 * logvar)\n",
        "            z = torch.cat([mu, sigma], dim=1)\n",
        "\n",
        "        with autocast(device_type=\"cuda\", dtype=torch.float16):\n",
        "            outputs = classifier(z)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        preds = (torch.sigmoid(outputs).detach().cpu().numpy() > 0.5)\n",
        "        all_preds.extend(preds.flatten())\n",
        "        all_labels.extend(labels.cpu().numpy().flatten())\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_classifier(classifier, vae_encoder, dataloader, criterion, device, threshold=0.5):\n",
        "    classifier.eval()\n",
        "    vae_encoder.eval()\n",
        "    total_loss = 0\n",
        "    all_probs, all_labels = [], []\n",
        "\n",
        "    for batch in dataloader:\n",
        "        data = batch[0].to(device)\n",
        "        labels = batch[1].float().unsqueeze(1).to(device)\n",
        "\n",
        "        mu, logvar = vae_encoder(data)\n",
        "        sigma = torch.exp(0.5 * logvar)\n",
        "        z = torch.cat([mu, sigma], dim=1)\n",
        "\n",
        "        with autocast(device_type=\"cuda\", dtype=torch.float16):\n",
        "            outputs = classifier(z)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        probs = torch.sigmoid(outputs).cpu().numpy()\n",
        "        all_probs.extend(probs.flatten())\n",
        "        all_labels.extend(labels.cpu().numpy().flatten())\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    all_probs = np.array(all_probs)\n",
        "    all_labels = np.array(all_labels)\n",
        "    preds = (all_probs >= threshold).astype(int)\n",
        "\n",
        "    acc = accuracy_score(all_labels, preds)\n",
        "    try:\n",
        "        auc = roc_auc_score(all_labels, all_probs)\n",
        "    except ValueError:\n",
        "        auc = 0.5\n",
        "        logging.warning(\"⚠️ Could not calculate AUC (possibly only one class present).\")\n",
        "\n",
        "    return avg_loss, acc, auc\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# --- Saliency Map Function ---\n",
        "\n",
        "def compute_saliency_maps(input_data, input_labels, vae_encoder, classifier, device):\n",
        "    \"\"\"Computes saliency maps for given data using the trained models.\"\"\"\n",
        "    vae_encoder.eval()\n",
        "    classifier.eval()\n",
        "\n",
        "    # Ensure input_data requires gradients\n",
        "    input_data = input_data.clone().detach().to(device).requires_grad_(True)\n",
        "    input_labels = input_labels.to(device).float().unsqueeze(1) # Ensure labels are float and shape [B, 1]\n",
        "\n",
        "\n",
        "    # Forward pass through encoder and classifier\n",
        "    mu, logvar = vae_encoder(input_data)\n",
        "    # Concatenate mu and sigma to match classifier input\n",
        "    sigma = torch.exp(0.5 * logvar)\n",
        "    z = torch.cat([mu, sigma], dim=1) #  ⬅️ concatenate mu & sigma\n",
        "\n",
        "    scores = classifier(z) # Logits\n",
        "\n",
        "    # Get the score for the target class (using labels to pick the correct score if multi-class)\n",
        "    # For binary classification with BCEWithLogitsLoss, the single output score is sufficient.\n",
        "    # We can calculate gradient w.r.t this score. Let's target the positive class implicitly.\n",
        "    # Or, more explicitly, if label=1, use score, if label=0, use -score? Simpler to just use the score.\n",
        "    scores.sum().backward() # Summing scores to get scalar for backward pass\n",
        "\n",
        "    # Get the gradient of the score with respect to the input\n",
        "    saliency = input_data.grad.data.abs() # Absolute value of gradients\n",
        "\n",
        "    return saliency.cpu()\n",
        "\n",
        "\n",
        "# --- Main Execution ---\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # 0. Scalers\n",
        "    vae_scaler = GradScaler()\n",
        "    clf_scaler = GradScaler()\n",
        "\n",
        "    # 1. Load Data\n",
        "    train_z, val_z, test_z, train_labels, val_labels, test_labels = load_fold_data(PROJECT_DIR, FOLD_NUMBER)\n",
        "\n",
        "    # Get data dimensions\n",
        "    N, C, H, W = train_z.shape\n",
        "    print(f\"Train data dimensions: N={N}, C={C}, H={H}, W={W}\")\n",
        "    N, C, H, W = val_z.shape\n",
        "    print(f\"Validation data dimensions: N={N}, C={C}, H={H}, W={W}\")\n",
        "    N, C, H, W = test_z.shape\n",
        "    print(f\"Test data dimensions: N={N}, C={C}, H={H}, W={W}\")\n",
        "\n",
        "    # Create DataLoader for VAE training (using all data)\n",
        "    #vae_dataset = TensorDataset(all_train_val_data)\n",
        "    #vae_dataloader = DataLoader(vae_dataset, batch_size=VAE_BATCH_SIZE, shuffle=True, pin_memory=True, num_workers=2)\n",
        "    #print(f\"VAE training dataset size: {len(vae_dataset)}\")\n",
        "    # ---------------- VAE DataLoaders -----------------\n",
        "    # Usar todo (train + val) para entrenar el VAE\n",
        "    all_train_data = torch.cat((train_z, val_z), dim=0)\n",
        "    vae_train_dataset = TensorDataset(all_train_data)\n",
        "    vae_train_loader = DataLoader(\n",
        "        vae_train_dataset, batch_size=VAE_BATCH_SIZE,\n",
        "        shuffle=True, pin_memory=True, num_workers=2\n",
        "    )\n",
        "\n",
        "    # Val_loader (opcional): usar val_z para monitorear validación (early stopping)\n",
        "    vae_val_dataset = TensorDataset(val_z)\n",
        "    vae_val_loader = DataLoader(\n",
        "        vae_val_dataset, batch_size=VAE_BATCH_SIZE,\n",
        "        shuffle=False, pin_memory=True, num_workers=2\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # 2. Initialize and Train Beta-VAE\n",
        "    vae = BetaVAE(input_channels=C, latent_dim=LATENT_DIM, h=H, w=W).to(DEVICE)\n",
        "    # Aceleración con torch.compile (requiere PyTorch >= 2.0)\n",
        "    try:\n",
        "        vae = torch.compile(vae)\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ torch.compile() failed: {e}\")\n",
        "    vae_optimizer = optim.AdamW(vae.parameters(), lr=VAE_LEARNING_RATE)\n",
        "    #vae_optimizer = optim.Adam(vae.parameters(), lr=VAE_LEARNING_RATE)\n",
        "\n",
        "    patience_vae   = 100\n",
        "    best_val_loss  = float('inf')\n",
        "    epochs_no_impr = 0\n",
        "    best_vae_state = None\n",
        "\n",
        "    for epoch in range(1, VAE_EPOCHS + 1):\n",
        "        tr_loss, tr_bce, tr_kld = train_vae(\n",
        "            vae, vae_train_loader, vae_optimizer, BETA,\n",
        "            DEVICE, vae_scaler, epoch)\n",
        "\n",
        "        val_loss, val_bce, val_kld = evaluate_vae(\n",
        "            vae, vae_val_loader, BETA, DEVICE)\n",
        "\n",
        "        if epoch % 10 == 0 or epoch == 1:\n",
        "            print(f\"[VAE] Ep {epoch}/{VAE_EPOCHS} \"\n",
        "                  f\"Train {tr_loss:.4f} | Val {val_loss:.4f}\")\n",
        "\n",
        "        # ---------- early stopping ----------\n",
        "        if val_loss < best_val_loss - 1e-7:      # pequeña mejora mínima\n",
        "            best_val_loss  = val_loss\n",
        "            epochs_no_impr = 0\n",
        "            best_vae_state = vae.state_dict()\n",
        "            print(f\"   ↪︎ New best val loss {best_val_loss:.4f}  (checkpoint)\")\n",
        "        else:\n",
        "            epochs_no_impr += 1\n",
        "            if epochs_no_impr >= patience_vae:\n",
        "                print(f\"   🛑 Early-stopping after {patience_vae} epochs \"\n",
        "                      f\"w/o improvement.\")\n",
        "                break\n",
        "\n",
        "\n",
        "        if epoch % 10 == 0 or epoch == VAE_EPOCHS:\n",
        "          # Corregir print\n",
        "          print(f'VAE Epoch: {epoch}/{VAE_EPOCHS} \\tLoss: {tr_loss:.4f} \\tRecon Loss: {tr_bce:.4f} \\tKL Div: {tr_kld:.4f}')\n",
        "    print(\"--- VAE Training Finished ---\")\n",
        "\n",
        "    # (Optional) Save VAE model\n",
        "    torch.save(vae.state_dict(), os.path.join(PROJECT_DIR, f\"beta_vae_fold{FOLD_NUMBER}.pt\"))\n",
        "    vae.load_state_dict(torch.load(os.path.join(PROJECT_DIR, f\"beta_vae_fold{FOLD_NUMBER}.pt\")))\n",
        "\n",
        "    # Después del entrenamiento\n",
        "    vae.load_state_dict(best_vae_state)\n",
        "\n",
        "\n",
        "\n",
        "    # Concatenar nuevamente los sets para classifier\n",
        "    all_train_val_data = torch.cat((train_z, val_z), dim=0)\n",
        "    all_train_val_labels = np.concatenate((train_labels, val_labels), axis=0)\n",
        "\n",
        "    # Para compatibilidad en test\n",
        "    test_data = test_z\n",
        "\n",
        "    # 3. Prepare Data for Classifier (AD vs CN only)\n",
        "    # Extract AD (label contains 'AD_') and CN (label contains 'CN_') subjects\n",
        "    ad_cn_indices_train_val = [i for i, lbl in enumerate(all_train_val_labels) if 'AD_' in lbl or 'CN_' in lbl]\n",
        "    ad_cn_indices_test = [i for i, lbl in enumerate(test_labels) if 'AD_' in lbl or 'CN_' in lbl]\n",
        "\n",
        "    train_val_ad_cn_data = all_train_val_data[ad_cn_indices_train_val]\n",
        "    train_val_ad_cn_labels_str = all_train_val_labels[ad_cn_indices_train_val]\n",
        "\n",
        "    test_ad_cn_data = test_data[ad_cn_indices_test]\n",
        "    test_ad_cn_labels_str = test_labels[ad_cn_indices_test]\n",
        "\n",
        "    # Convert string labels to binary (e.g., AD=1, CN=0)\n",
        "    train_val_ad_cn_labels_bin = torch.tensor([1 if 'AD_' in lbl else 0 for lbl in train_val_ad_cn_labels_str], dtype=torch.long)\n",
        "    test_ad_cn_labels_bin = torch.tensor([1 if 'AD_' in lbl else 0 for lbl in test_ad_cn_labels_str], dtype=torch.long)\n",
        "\n",
        "    print(f\"AD/CN Train/Val data shape: {train_val_ad_cn_data.shape}\")\n",
        "    print(f\"AD/CN Test data shape: {test_ad_cn_data.shape}\")\n",
        "\n",
        "\n",
        "    # Split AD/CN train_val further into train and validation sets for the classifier\n",
        "    if len(train_val_ad_cn_data) > 1: # Need at least 2 samples for split\n",
        "      train_indices, val_indices = train_test_split(\n",
        "          range(len(train_val_ad_cn_data)),\n",
        "          test_size=0.2, # 20% for validation\n",
        "          random_state=SEED,\n",
        "          stratify=train_val_ad_cn_labels_bin.numpy() # Stratify based on AD/CN\n",
        "      )\n",
        "\n",
        "      clf_train_data = train_val_ad_cn_data[train_indices]\n",
        "      clf_train_labels = train_val_ad_cn_labels_bin[train_indices]\n",
        "      clf_val_data = train_val_ad_cn_data[val_indices]\n",
        "      clf_val_labels = train_val_ad_cn_labels_bin[val_indices]\n",
        "    else:\n",
        "      logging.warning(\"Not enough AD/CN data in train/val set to create a validation split. Using all for training.\")\n",
        "      clf_train_data = train_val_ad_cn_data\n",
        "      clf_train_labels = train_val_ad_cn_labels_bin\n",
        "      clf_val_data = train_val_ad_cn_data # Use same data for validation eval (not ideal)\n",
        "      clf_val_labels = train_val_ad_cn_labels_bin\n",
        "\n",
        "\n",
        "    clf_train_dataset = TensorDataset(clf_train_data, clf_train_labels)\n",
        "    clf_val_dataset = TensorDataset(clf_val_data, clf_val_labels)\n",
        "    clf_test_dataset = TensorDataset(test_ad_cn_data, test_ad_cn_labels_bin)\n",
        "\n",
        "    clf_train_dataloader = DataLoader(clf_train_dataset, batch_size=CLASSIFIER_BATCH_SIZE, shuffle=True, pin_memory=True, num_workers=2)\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "    plt.savefig(os.path.join(PROJECT_DIR, f\"avg_saliency_map_fold{FOLD_NUMBER}.png\"))\n",
        "    print(f\"Saved average saliency map visualization to {PROJECT_DIR}\")\n",
        "    plt.show() # Uncomment to display plot directly if running interactively\n",
        "\n",
        "\n",
        "    print(\"--- Analysis Complete ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LC8I4eDrT6_R",
        "outputId": "a3ae8f0a-b239-4b30-c396-757d9ca06df5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Loading data from /content/drive/MyDrive/GrandMeanNorm/fold_1\n",
            "Train data shape: torch.Size([276, 4, 166, 166])\n",
            "Validation data shape: torch.Size([69, 4, 166, 166])\n",
            "Test data shape: torch.Size([87, 4, 166, 166])\n",
            "Train data dimensions: N=276, C=4, H=166, W=166\n",
            "Validation data dimensions: N=69, C=4, H=166, W=166\n",
            "Test data dimensions: N=87, C=4, H=166, W=166\n",
            "[VAE] Ep 1/8500 Train 128008.5599 | Val 124072.2188\n",
            "   ↪︎ New best val loss 124072.2188  (checkpoint)\n",
            "[VAE] Ep 10/8500 Train 104473.3958 | Val 125989.6172\n",
            "VAE Epoch: 10/8500 \tLoss: 104473.3958 \tRecon Loss: 104344.3086 \tKL Div: 329.1731\n",
            "   ↪︎ New best val loss 116916.7695  (checkpoint)\n",
            "   ↪︎ New best val loss 113895.9414  (checkpoint)\n",
            "   ↪︎ New best val loss 109683.9844  (checkpoint)\n",
            "   ↪︎ New best val loss 108668.8281  (checkpoint)\n",
            "   ↪︎ New best val loss 106556.5781  (checkpoint)\n",
            "   ↪︎ New best val loss 104982.4688  (checkpoint)\n",
            "   ↪︎ New best val loss 103874.4453  (checkpoint)\n",
            "[VAE] Ep 20/8500 Train 88234.3268 | Val 103460.4492\n",
            "   ↪︎ New best val loss 103460.4492  (checkpoint)\n",
            "VAE Epoch: 20/8500 \tLoss: 88234.3268 \tRecon Loss: 88079.1185 \tKL Div: 197.8902\n",
            "   ↪︎ New best val loss 103122.4648  (checkpoint)\n",
            "   ↪︎ New best val loss 103107.7422  (checkpoint)\n",
            "   ↪︎ New best val loss 102032.8984  (checkpoint)\n",
            "   ↪︎ New best val loss 101277.4766  (checkpoint)\n",
            "   ↪︎ New best val loss 100586.5859  (checkpoint)\n",
            "   ↪︎ New best val loss 100189.1406  (checkpoint)\n",
            "[VAE] Ep 30/8500 Train 85704.7266 | Val 98909.1758\n",
            "   ↪︎ New best val loss 98909.1758  (checkpoint)\n",
            "VAE Epoch: 30/8500 \tLoss: 85704.7266 \tRecon Loss: 85508.4089 \tKL Div: 166.8704\n",
            "   ↪︎ New best val loss 98147.7852  (checkpoint)\n",
            "   ↪︎ New best val loss 98013.6641  (checkpoint)\n",
            "   ↪︎ New best val loss 97330.7773  (checkpoint)\n",
            "   ↪︎ New best val loss 97157.7930  (checkpoint)\n",
            "   ↪︎ New best val loss 95930.6094  (checkpoint)\n",
            "   ↪︎ New best val loss 95733.3984  (checkpoint)\n",
            "[VAE] Ep 40/8500 Train 85663.9857 | Val 96057.4844\n",
            "VAE Epoch: 40/8500 \tLoss: 85663.9857 \tRecon Loss: 85439.9167 \tKL Div: 142.8434\n",
            "   ↪︎ New best val loss 94858.0156  (checkpoint)\n",
            "   ↪︎ New best val loss 93963.7305  (checkpoint)\n",
            "   ↪︎ New best val loss 93788.4414  (checkpoint)\n",
            "   ↪︎ New best val loss 93459.8164  (checkpoint)\n",
            "[VAE] Ep 50/8500 Train 84819.1992 | Val 93288.8906\n",
            "   ↪︎ New best val loss 93288.8906  (checkpoint)\n",
            "VAE Epoch: 50/8500 \tLoss: 84819.1992 \tRecon Loss: 84578.4492 \tKL Div: 122.7833\n",
            "   ↪︎ New best val loss 93081.6914  (checkpoint)\n",
            "   ↪︎ New best val loss 92692.4531  (checkpoint)\n",
            "   ↪︎ New best val loss 92629.6875  (checkpoint)\n",
            "   ↪︎ New best val loss 92514.3750  (checkpoint)\n",
            "   ↪︎ New best val loss 92063.6992  (checkpoint)\n",
            "   ↪︎ New best val loss 91859.7969  (checkpoint)\n",
            "[VAE] Ep 60/8500 Train 83060.0234 | Val 91883.9414\n",
            "VAE Epoch: 60/8500 \tLoss: 83060.0234 \tRecon Loss: 82777.2174 \tKL Div: 120.1918\n",
            "   ↪︎ New best val loss 91398.6914  (checkpoint)\n",
            "   ↪︎ New best val loss 90771.9453  (checkpoint)\n",
            "[VAE] Ep 70/8500 Train 82525.0469 | Val 90657.7852\n",
            "   ↪︎ New best val loss 90657.7852  (checkpoint)\n",
            "VAE Epoch: 70/8500 \tLoss: 82525.0469 \tRecon Loss: 82224.1784 \tKL Div: 109.6026\n",
            "   ↪︎ New best val loss 90504.7656  (checkpoint)\n",
            "   ↪︎ New best val loss 90437.4297  (checkpoint)\n",
            "[VAE] Ep 80/8500 Train 81679.5898 | Val 90298.6094\n",
            "   ↪︎ New best val loss 90298.6094  (checkpoint)\n",
            "VAE Epoch: 80/8500 \tLoss: 81679.5898 \tRecon Loss: 81315.0299 \tKL Div: 116.2035\n",
            "   ↪︎ New best val loss 89964.1406  (checkpoint)\n",
            "   ↪︎ New best val loss 89135.2969  (checkpoint)\n",
            "[VAE] Ep 90/8500 Train 81354.4518 | Val 88807.6055\n",
            "   ↪︎ New best val loss 88807.6055  (checkpoint)\n",
            "VAE Epoch: 90/8500 \tLoss: 81354.4518 \tRecon Loss: 80947.7708 \tKL Div: 115.2261\n",
            "   ↪︎ New best val loss 88400.9336  (checkpoint)\n",
            "[VAE] Ep 100/8500 Train 80411.8073 | Val 88771.3828\n",
            "VAE Epoch: 100/8500 \tLoss: 80411.8073 \tRecon Loss: 79953.5026 \tKL Div: 116.8675\n",
            "   ↪︎ New best val loss 88140.0547  (checkpoint)\n",
            "   ↪︎ New best val loss 87722.1211  (checkpoint)\n",
            "   ↪︎ New best val loss 87690.4883  (checkpoint)\n",
            "   ↪︎ New best val loss 87574.5039  (checkpoint)\n",
            "[VAE] Ep 110/8500 Train 79856.0234 | Val 87441.9375\n",
            "   ↪︎ New best val loss 87441.9375  (checkpoint)\n",
            "VAE Epoch: 110/8500 \tLoss: 79856.0234 \tRecon Loss: 79397.3372 \tKL Div: 106.3319\n",
            "   ↪︎ New best val loss 87349.1641  (checkpoint)\n",
            "   ↪︎ New best val loss 87046.7344  (checkpoint)\n",
            "   ↪︎ New best val loss 87045.3047  (checkpoint)\n",
            "   ↪︎ New best val loss 86898.7852  (checkpoint)\n",
            "   ↪︎ New best val loss 86718.5391  (checkpoint)\n",
            "[VAE] Ep 120/8500 Train 79307.4427 | Val 86912.1367\n",
            "VAE Epoch: 120/8500 \tLoss: 79307.4427 \tRecon Loss: 78802.8255 \tKL Div: 107.2312\n",
            "   ↪︎ New best val loss 86337.4648  (checkpoint)\n",
            "   ↪︎ New best val loss 86269.6016  (checkpoint)\n",
            "   ↪︎ New best val loss 86216.1562  (checkpoint)\n",
            "[VAE] Ep 130/8500 Train 78485.6484 | Val 86272.7422\n",
            "VAE Epoch: 130/8500 \tLoss: 78485.6484 \tRecon Loss: 77936.1940 \tKL Div: 107.7780\n",
            "   ↪︎ New best val loss 86055.3516  (checkpoint)\n",
            "   ↪︎ New best val loss 86035.3633  (checkpoint)\n",
            "   ↪︎ New best val loss 85954.1172  (checkpoint)\n",
            "   ↪︎ New best val loss 85784.9766  (checkpoint)\n",
            "[VAE] Ep 140/8500 Train 77923.7148 | Val 86096.5469\n",
            "VAE Epoch: 140/8500 \tLoss: 77923.7148 \tRecon Loss: 77339.5430 \tKL Div: 106.4029\n",
            "   ↪︎ New best val loss 85459.3672  (checkpoint)\n",
            "   ↪︎ New best val loss 85385.3203  (checkpoint)\n",
            "   ↪︎ New best val loss 84916.9922  (checkpoint)\n",
            "[VAE] Ep 150/8500 Train 77328.9922 | Val 85547.1484\n",
            "VAE Epoch: 150/8500 \tLoss: 77328.9922 \tRecon Loss: 76682.1315 \tKL Div: 109.9665\n",
            "   ↪︎ New best val loss 84879.6836  (checkpoint)\n",
            "   ↪︎ New best val loss 84564.8906  (checkpoint)\n",
            "[VAE] Ep 160/8500 Train 76276.6849 | Val 84681.6875\n",
            "VAE Epoch: 160/8500 \tLoss: 76276.6849 \tRecon Loss: 75577.6393 \tKL Div: 111.4103\n",
            "   ↪︎ New best val loss 84531.5391  (checkpoint)\n",
            "   ↪︎ New best val loss 84252.3945  (checkpoint)\n",
            "   ↪︎ New best val loss 83935.8320  (checkpoint)\n",
            "[VAE] Ep 170/8500 Train 75842.3828 | Val 84690.1289\n",
            "VAE Epoch: 170/8500 \tLoss: 75842.3828 \tRecon Loss: 75092.6810 \tKL Div: 112.4551\n",
            "[VAE] Ep 180/8500 Train 74810.0977 | Val 84144.1016\n",
            "VAE Epoch: 180/8500 \tLoss: 74810.0977 \tRecon Loss: 73974.5143 \tKL Div: 118.3742\n",
            "   ↪︎ New best val loss 83766.7109  (checkpoint)\n",
            "   ↪︎ New best val loss 83488.4766  (checkpoint)\n",
            "   ↪︎ New best val loss 83375.8594  (checkpoint)\n",
            "   ↪︎ New best val loss 83357.1445  (checkpoint)\n",
            "[VAE] Ep 190/8500 Train 74163.1732 | Val 83471.0664\n",
            "VAE Epoch: 190/8500 \tLoss: 74163.1732 \tRecon Loss: 73306.0820 \tKL Div: 115.0306\n",
            "   ↪︎ New best val loss 83132.5156  (checkpoint)\n",
            "   ↪︎ New best val loss 82977.3125  (checkpoint)\n",
            "   ↪︎ New best val loss 82782.4375  (checkpoint)\n",
            "   ↪︎ New best val loss 82678.7188  (checkpoint)\n",
            "   ↪︎ New best val loss 82223.4258  (checkpoint)\n",
            "[VAE] Ep 200/8500 Train 73240.9792 | Val 82704.2422\n",
            "VAE Epoch: 200/8500 \tLoss: 73240.9792 \tRecon Loss: 72317.4948 \tKL Div: 117.7445\n",
            "   ↪︎ New best val loss 82168.7344  (checkpoint)\n",
            "[VAE] Ep 210/8500 Train 73300.9818 | Val 82541.3164\n",
            "VAE Epoch: 210/8500 \tLoss: 73300.9818 \tRecon Loss: 72290.5872 \tKL Div: 122.6906\n",
            "   ↪︎ New best val loss 82168.6836  (checkpoint)\n",
            "   ↪︎ New best val loss 82028.1211  (checkpoint)\n",
            "   ↪︎ New best val loss 81724.3047  (checkpoint)\n",
            "   ↪︎ New best val loss 81391.2305  (checkpoint)\n",
            "[VAE] Ep 220/8500 Train 72197.8724 | Val 81738.7852\n",
            "VAE Epoch: 220/8500 \tLoss: 72197.8724 \tRecon Loss: 71138.2435 \tKL Div: 122.8206\n",
            "   ↪︎ New best val loss 81178.0781  (checkpoint)\n",
            "   ↪︎ New best val loss 80989.0938  (checkpoint)\n",
            "[VAE] Ep 230/8500 Train 71345.2227 | Val 80606.1758\n",
            "   ↪︎ New best val loss 80606.1758  (checkpoint)\n",
            "VAE Epoch: 230/8500 \tLoss: 71345.2227 \tRecon Loss: 70241.3359 \tKL Div: 122.3875\n",
            "   ↪︎ New best val loss 80521.7266  (checkpoint)\n",
            "   ↪︎ New best val loss 80398.2188  (checkpoint)\n",
            "[VAE] Ep 240/8500 Train 71082.8112 | Val 80739.0430\n",
            "VAE Epoch: 240/8500 \tLoss: 71082.8112 \tRecon Loss: 69948.9714 \tKL Div: 120.4704\n",
            "   ↪︎ New best val loss 80193.1250  (checkpoint)\n",
            "   ↪︎ New best val loss 79950.4180  (checkpoint)\n",
            "[VAE] Ep 250/8500 Train 70603.1497 | Val 79700.6953\n",
            "   ↪︎ New best val loss 79700.6953  (checkpoint)\n",
            "VAE Epoch: 250/8500 \tLoss: 70603.1497 \tRecon Loss: 69407.6042 \tKL Div: 121.9457\n",
            "   ↪︎ New best val loss 79558.4766  (checkpoint)\n",
            "   ↪︎ New best val loss 79254.4922  (checkpoint)\n",
            "   ↪︎ New best val loss 79030.5703  (checkpoint)\n",
            "[VAE] Ep 260/8500 Train 70234.2760 | Val 78947.6445\n",
            "   ↪︎ New best val loss 78947.6445  (checkpoint)\n",
            "VAE Epoch: 260/8500 \tLoss: 70234.2760 \tRecon Loss: 68990.1771 \tKL Div: 122.0174\n",
            "   ↪︎ New best val loss 78731.3984  (checkpoint)\n",
            "   ↪︎ New best val loss 78343.6172  (checkpoint)\n",
            "[VAE] Ep 270/8500 Train 69558.5560 | Val 78794.5078\n",
            "VAE Epoch: 270/8500 \tLoss: 69558.5560 \tRecon Loss: 68293.3112 \tKL Div: 119.4955\n",
            "   ↪︎ New best val loss 78271.6250  (checkpoint)\n",
            "   ↪︎ New best val loss 78087.5742  (checkpoint)\n",
            "[VAE] Ep 280/8500 Train 70040.5977 | Val 78714.0898\n",
            "VAE Epoch: 280/8500 \tLoss: 70040.5977 \tRecon Loss: 68755.8646 \tKL Div: 117.0025\n",
            "   ↪︎ New best val loss 78023.3984  (checkpoint)\n",
            "   ↪︎ New best val loss 77943.6562  (checkpoint)\n",
            "   ↪︎ New best val loss 77580.4766  (checkpoint)\n",
            "[VAE] Ep 290/8500 Train 68832.1901 | Val 77912.8711\n",
            "VAE Epoch: 290/8500 \tLoss: 68832.1901 \tRecon Loss: 67485.4974 \tKL Div: 118.4160\n",
            "   ↪︎ New best val loss 77487.0000  (checkpoint)\n",
            "   ↪︎ New best val loss 77324.1367  (checkpoint)\n",
            "   ↪︎ New best val loss 77285.6328  (checkpoint)\n",
            "   ↪︎ New best val loss 77004.0898  (checkpoint)\n",
            "[VAE] Ep 300/8500 Train 68883.6953 | Val 77455.8711\n",
            "VAE Epoch: 300/8500 \tLoss: 68883.6953 \tRecon Loss: 67529.9258 \tKL Div: 115.0704\n",
            "   ↪︎ New best val loss 76786.1875  (checkpoint)\n",
            "   ↪︎ New best val loss 76784.7344  (checkpoint)\n",
            "   ↪︎ New best val loss 76643.1602  (checkpoint)\n",
            "[VAE] Ep 310/8500 Train 68418.0534 | Val 76931.3789\n",
            "VAE Epoch: 310/8500 \tLoss: 68418.0534 \tRecon Loss: 67008.4036 \tKL Div: 115.9552\n",
            "   ↪︎ New best val loss 76491.2812  (checkpoint)\n",
            "   ↪︎ New best val loss 76371.8438  (checkpoint)\n",
            "[VAE] Ep 320/8500 Train 68890.5026 | Val 78168.5547\n",
            "VAE Epoch: 320/8500 \tLoss: 68890.5026 \tRecon Loss: 67485.4648 \tKL Div: 111.9640\n",
            "   ↪︎ New best val loss 75800.2617  (checkpoint)\n",
            "[VAE] Ep 330/8500 Train 68004.5312 | Val 76150.4961\n",
            "VAE Epoch: 330/8500 \tLoss: 68004.5312 \tRecon Loss: 66571.5729 \tKL Div: 110.7285\n",
            "   ↪︎ New best val loss 75578.9258  (checkpoint)\n",
            "   ↪︎ New best val loss 75156.0000  (checkpoint)\n",
            "[VAE] Ep 340/8500 Train 67619.6484 | Val 75334.7891\n",
            "VAE Epoch: 340/8500 \tLoss: 67619.6484 \tRecon Loss: 66167.0221 \tKL Div: 108.9470\n",
            "   ↪︎ New best val loss 74983.7305  (checkpoint)\n",
            "[VAE] Ep 350/8500 Train 67418.2591 | Val 74820.9141\n",
            "   ↪︎ New best val loss 74820.9141  (checkpoint)\n",
            "VAE Epoch: 350/8500 \tLoss: 67418.2591 \tRecon Loss: 65940.1960 \tKL Div: 107.6875\n",
            "   ↪︎ New best val loss 74801.7695  (checkpoint)\n",
            "   ↪︎ New best val loss 74660.7578  (checkpoint)\n",
            "[VAE] Ep 360/8500 Train 67224.0339 | Val 74767.7734\n",
            "VAE Epoch: 360/8500 \tLoss: 67224.0339 \tRecon Loss: 65721.6016 \tKL Div: 106.4223\n",
            "   ↪︎ New best val loss 74277.0820  (checkpoint)\n",
            "[VAE] Ep 370/8500 Train 67393.5755 | Val 75164.0156\n",
            "VAE Epoch: 370/8500 \tLoss: 67393.5755 \tRecon Loss: 65901.6061 \tKL Div: 102.8250\n",
            "   ↪︎ New best val loss 74197.5938  (checkpoint)\n",
            "   ↪︎ New best val loss 74166.3477  (checkpoint)\n",
            "[VAE] Ep 380/8500 Train 66625.5352 | Val 74260.1562\n",
            "VAE Epoch: 380/8500 \tLoss: 66625.5352 \tRecon Loss: 65081.0176 \tKL Div: 103.6452\n",
            "   ↪︎ New best val loss 74129.8086  (checkpoint)\n",
            "   ↪︎ New best val loss 74100.8945  (checkpoint)\n",
            "   ↪︎ New best val loss 73747.6797  (checkpoint)\n",
            "   ↪︎ New best val loss 73658.0625  (checkpoint)\n",
            "   ↪︎ New best val loss 73502.2070  (checkpoint)\n",
            "[VAE] Ep 390/8500 Train 66718.8796 | Val 73517.4180\n",
            "VAE Epoch: 390/8500 \tLoss: 66718.8796 \tRecon Loss: 65176.8861 \tKL Div: 100.8227\n",
            "   ↪︎ New best val loss 73295.4766  (checkpoint)\n",
            "[VAE] Ep 400/8500 Train 66412.9486 | Val 73446.7812\n",
            "VAE Epoch: 400/8500 \tLoss: 66412.9486 \tRecon Loss: 64852.8509 \tKL Div: 99.4562\n",
            "   ↪︎ New best val loss 73245.7031  (checkpoint)\n",
            "   ↪︎ New best val loss 72934.0664  (checkpoint)\n",
            "[VAE] Ep 410/8500 Train 66428.4004 | Val 73590.2617\n",
            "VAE Epoch: 410/8500 \tLoss: 66428.4004 \tRecon Loss: 64816.4557 \tKL Div: 100.2551\n",
            "   ↪︎ New best val loss 72758.4062  (checkpoint)\n",
            "   ↪︎ New best val loss 72677.5469  (checkpoint)\n",
            "   ↪︎ New best val loss 72594.5078  (checkpoint)\n",
            "[VAE] Ep 420/8500 Train 66349.2357 | Val 73245.2617\n",
            "VAE Epoch: 420/8500 \tLoss: 66349.2357 \tRecon Loss: 64762.1074 \tKL Div: 96.3612\n",
            "   ↪︎ New best val loss 72434.5195  (checkpoint)\n",
            "[VAE] Ep 430/8500 Train 66034.7474 | Val 72948.6094\n",
            "VAE Epoch: 430/8500 \tLoss: 66034.7474 \tRecon Loss: 64398.6875 \tKL Div: 97.0221\n",
            "   ↪︎ New best val loss 72378.9648  (checkpoint)\n",
            "   ↪︎ New best val loss 72269.5859  (checkpoint)\n",
            "   ↪︎ New best val loss 72013.4570  (checkpoint)\n",
            "[VAE] Ep 440/8500 Train 65770.9251 | Val 72122.2734\n",
            "VAE Epoch: 440/8500 \tLoss: 65770.9251 \tRecon Loss: 64139.9251 \tKL Div: 94.5238\n",
            "   ↪︎ New best val loss 71928.9844  (checkpoint)\n",
            "   ↪︎ New best val loss 71732.7148  (checkpoint)\n",
            "[VAE] Ep 450/8500 Train 65664.7077 | Val 71956.4062\n",
            "VAE Epoch: 450/8500 \tLoss: 65664.7077 \tRecon Loss: 64018.9753 \tKL Div: 93.2581\n",
            "   ↪︎ New best val loss 71703.7734  (checkpoint)\n",
            "   ↪︎ New best val loss 71575.1211  (checkpoint)\n",
            "[VAE] Ep 460/8500 Train 65652.0430 | Val 71517.8594\n",
            "   ↪︎ New best val loss 71517.8594  (checkpoint)\n",
            "VAE Epoch: 460/8500 \tLoss: 65652.0430 \tRecon Loss: 63971.4401 \tKL Div: 93.1638\n",
            "   ↪︎ New best val loss 71390.3398  (checkpoint)\n",
            "   ↪︎ New best val loss 71251.2891  (checkpoint)\n",
            "   ↪︎ New best val loss 71182.8086  (checkpoint)\n",
            "[VAE] Ep 470/8500 Train 65229.2448 | Val 70981.9961\n",
            "   ↪︎ New best val loss 70981.9961  (checkpoint)\n",
            "VAE Epoch: 470/8500 \tLoss: 65229.2448 \tRecon Loss: 63585.2220 \tKL Div: 89.1970\n",
            "   ↪︎ New best val loss 70939.8672  (checkpoint)\n",
            "[VAE] Ep 480/8500 Train 65295.0378 | Val 71062.9961\n",
            "VAE Epoch: 480/8500 \tLoss: 65295.0378 \tRecon Loss: 63619.5514 \tKL Div: 89.0103\n",
            "   ↪︎ New best val loss 70915.0234  (checkpoint)\n",
            "   ↪︎ New best val loss 70745.5938  (checkpoint)\n",
            "[VAE] Ep 490/8500 Train 65174.5853 | Val 71218.8203\n",
            "VAE Epoch: 490/8500 \tLoss: 65174.5853 \tRecon Loss: 63477.5957 \tKL Div: 88.3126\n",
            "   ↪︎ New best val loss 70668.1289  (checkpoint)\n",
            "   ↪︎ New best val loss 70565.2188  (checkpoint)\n",
            "[VAE] Ep 500/8500 Train 65098.9245 | Val 70849.7500\n",
            "VAE Epoch: 500/8500 \tLoss: 65098.9245 \tRecon Loss: 63355.1556 \tKL Div: 88.9322\n",
            "[VAE] Ep 510/8500 Train 65246.0228 | Val 70508.0352\n",
            "   ↪︎ New best val loss 70508.0352  (checkpoint)\n",
            "VAE Epoch: 510/8500 \tLoss: 65246.0228 \tRecon Loss: 63526.5189 \tKL Div: 85.9752\n",
            "   ↪︎ New best val loss 70445.6602  (checkpoint)\n",
            "   ↪︎ New best val loss 70160.3086  (checkpoint)\n",
            "[VAE] Ep 520/8500 Train 65060.9824 | Val 70143.2383\n",
            "   ↪︎ New best val loss 70143.2383  (checkpoint)\n",
            "VAE Epoch: 520/8500 \tLoss: 65060.9824 \tRecon Loss: 63320.2311 \tKL Div: 85.3637\n",
            "   ↪︎ New best val loss 70075.8008  (checkpoint)\n",
            "   ↪︎ New best val loss 69996.8711  (checkpoint)\n",
            "   ↪︎ New best val loss 69919.5508  (checkpoint)\n",
            "[VAE] Ep 530/8500 Train 64751.1530 | Val 69745.9961\n",
            "   ↪︎ New best val loss 69745.9961  (checkpoint)\n",
            "VAE Epoch: 530/8500 \tLoss: 64751.1530 \tRecon Loss: 62979.6393 \tKL Div: 85.2332\n",
            "   ↪︎ New best val loss 69710.3242  (checkpoint)\n",
            "[VAE] Ep 540/8500 Train 64763.2969 | Val 69958.8555\n",
            "VAE Epoch: 540/8500 \tLoss: 64763.2969 \tRecon Loss: 62987.9486 \tKL Div: 83.8359\n",
            "   ↪︎ New best val loss 69700.8633  (checkpoint)\n",
            "   ↪︎ New best val loss 69538.4961  (checkpoint)\n",
            "[VAE] Ep 550/8500 Train 64676.1139 | Val 69636.5508\n",
            "VAE Epoch: 550/8500 \tLoss: 64676.1139 \tRecon Loss: 62893.6100 \tKL Div: 82.6434\n",
            "   ↪︎ New best val loss 69321.2812  (checkpoint)\n",
            "[VAE] Ep 560/8500 Train 64624.3509 | Val 69804.9336\n",
            "VAE Epoch: 560/8500 \tLoss: 64624.3509 \tRecon Loss: 62809.4518 \tKL Div: 82.6427\n",
            "   ↪︎ New best val loss 69077.0508  (checkpoint)\n",
            "   ↪︎ New best val loss 69035.1719  (checkpoint)\n",
            "   ↪︎ New best val loss 68932.9375  (checkpoint)\n",
            "[VAE] Ep 570/8500 Train 64244.6523 | Val 69055.7539\n",
            "VAE Epoch: 570/8500 \tLoss: 64244.6523 \tRecon Loss: 62485.2806 \tKL Div: 78.7087\n",
            "[VAE] Ep 580/8500 Train 64112.0365 | Val 68991.9922\n",
            "VAE Epoch: 580/8500 \tLoss: 64112.0365 \tRecon Loss: 62311.0365 \tKL Div: 79.1819\n",
            "   ↪︎ New best val loss 68807.8008  (checkpoint)\n",
            "[VAE] Ep 590/8500 Train 64337.7676 | Val 69145.2227\n",
            "VAE Epoch: 590/8500 \tLoss: 64337.7676 \tRecon Loss: 62507.7311 \tKL Div: 79.0948\n",
            "   ↪︎ New best val loss 68728.1172  (checkpoint)\n",
            "   ↪︎ New best val loss 68660.5234  (checkpoint)\n",
            "[VAE] Ep 600/8500 Train 64185.6764 | Val 69066.8867\n",
            "VAE Epoch: 600/8500 \tLoss: 64185.6764 \tRecon Loss: 62346.1940 \tKL Div: 78.1780\n",
            "   ↪︎ New best val loss 68508.8633  (checkpoint)\n",
            "   ↪︎ New best val loss 68413.2305  (checkpoint)\n",
            "[VAE] Ep 610/8500 Train 63945.4512 | Val 68405.4961\n",
            "   ↪︎ New best val loss 68405.4961  (checkpoint)\n",
            "VAE Epoch: 610/8500 \tLoss: 63945.4512 \tRecon Loss: 62091.8815 \tKL Div: 77.4853\n",
            "   ↪︎ New best val loss 68377.4961  (checkpoint)\n",
            "   ↪︎ New best val loss 68321.7695  (checkpoint)\n",
            "   ↪︎ New best val loss 68260.0469  (checkpoint)\n",
            "[VAE] Ep 620/8500 Train 63856.6673 | Val 68320.2734\n",
            "VAE Epoch: 620/8500 \tLoss: 63856.6673 \tRecon Loss: 62003.3223 \tKL Div: 76.2263\n",
            "   ↪︎ New best val loss 68227.0000  (checkpoint)\n",
            "   ↪︎ New best val loss 68044.8906  (checkpoint)\n",
            "[VAE] Ep 630/8500 Train 63797.4225 | Val 68292.5117\n",
            "VAE Epoch: 630/8500 \tLoss: 63797.4225 \tRecon Loss: 61923.8079 \tKL Div: 75.8368\n",
            "   ↪︎ New best val loss 67983.6602  (checkpoint)\n",
            "   ↪︎ New best val loss 67752.3008  (checkpoint)\n",
            "[VAE] Ep 640/8500 Train 63746.9590 | Val 68169.3242\n",
            "VAE Epoch: 640/8500 \tLoss: 63746.9590 \tRecon Loss: 61843.0449 \tKL Div: 75.8591\n",
            "   ↪︎ New best val loss 67728.5000  (checkpoint)\n",
            "[VAE] Ep 650/8500 Train 63639.4486 | Val 67674.1641\n",
            "   ↪︎ New best val loss 67674.1641  (checkpoint)\n",
            "VAE Epoch: 650/8500 \tLoss: 63639.4486 \tRecon Loss: 61761.7845 \tKL Div: 73.6622\n",
            "   ↪︎ New best val loss 67502.7695  (checkpoint)\n",
            "[VAE] Ep 660/8500 Train 63716.9349 | Val 67750.9453\n",
            "VAE Epoch: 660/8500 \tLoss: 63716.9349 \tRecon Loss: 61805.0514 \tKL Div: 73.8682\n",
            "[VAE] Ep 670/8500 Train 63869.5853 | Val 67913.8750\n",
            "VAE Epoch: 670/8500 \tLoss: 63869.5853 \tRecon Loss: 61933.7923 \tKL Div: 73.6757\n",
            "   ↪︎ New best val loss 67412.6250  (checkpoint)\n",
            "[VAE] Ep 680/8500 Train 63574.9642 | Val 67431.7852\n",
            "VAE Epoch: 680/8500 \tLoss: 63574.9642 \tRecon Loss: 61678.9284 \tKL Div: 71.1013\n",
            "[VAE] Ep 690/8500 Train 63425.0436 | Val 67614.2422\n",
            "VAE Epoch: 690/8500 \tLoss: 63425.0436 \tRecon Loss: 61481.0228 \tKL Div: 71.8442\n",
            "   ↪︎ New best val loss 67327.0781  (checkpoint)\n",
            "   ↪︎ New best val loss 67162.6016  (checkpoint)\n",
            "   ↪︎ New best val loss 67152.3633  (checkpoint)\n",
            "[VAE] Ep 700/8500 Train 63350.7331 | Val 67144.0078\n",
            "   ↪︎ New best val loss 67144.0078  (checkpoint)\n",
            "VAE Epoch: 700/8500 \tLoss: 63350.7331 \tRecon Loss: 61376.2279 \tKL Div: 71.9284\n",
            "   ↪︎ New best val loss 67051.0859  (checkpoint)\n",
            "   ↪︎ New best val loss 67038.3516  (checkpoint)\n",
            "[VAE] Ep 710/8500 Train 63475.8750 | Val 66899.5742\n",
            "   ↪︎ New best val loss 66899.5742  (checkpoint)\n",
            "VAE Epoch: 710/8500 \tLoss: 63475.8750 \tRecon Loss: 61496.6816 \tKL Div: 71.0837\n",
            "   ↪︎ New best val loss 66892.3906  (checkpoint)\n",
            "[VAE] Ep 720/8500 Train 63686.6712 | Val 67952.3086\n",
            "VAE Epoch: 720/8500 \tLoss: 63686.6712 \tRecon Loss: 61719.6380 \tKL Div: 69.6657\n",
            "   ↪︎ New best val loss 66863.0352  (checkpoint)\n",
            "   ↪︎ New best val loss 66822.2266  (checkpoint)\n",
            "[VAE] Ep 730/8500 Train 63369.8965 | Val 66912.0938\n",
            "VAE Epoch: 730/8500 \tLoss: 63369.8965 \tRecon Loss: 61374.2897 \tKL Div: 69.7096\n",
            "   ↪︎ New best val loss 66809.2891  (checkpoint)\n",
            "   ↪︎ New best val loss 66678.5703  (checkpoint)\n",
            "[VAE] Ep 740/8500 Train 63066.8607 | Val 66690.9883\n",
            "VAE Epoch: 740/8500 \tLoss: 63066.8607 \tRecon Loss: 61025.1497 \tKL Div: 70.3562\n",
            "   ↪︎ New best val loss 66669.6016  (checkpoint)\n",
            "   ↪︎ New best val loss 66593.5664  (checkpoint)\n",
            "[VAE] Ep 750/8500 Train 62986.1022 | Val 66955.5273\n",
            "VAE Epoch: 750/8500 \tLoss: 62986.1022 \tRecon Loss: 60943.4368 \tKL Div: 69.4506\n",
            "[VAE] Ep 760/8500 Train 63093.3125 | Val 66524.1133\n",
            "   ↪︎ New best val loss 66524.1133  (checkpoint)\n",
            "VAE Epoch: 760/8500 \tLoss: 63093.3125 \tRecon Loss: 61039.6725 \tKL Div: 68.9050\n",
            "   ↪︎ New best val loss 66518.6094  (checkpoint)\n",
            "   ↪︎ New best val loss 66407.2969  (checkpoint)\n",
            "[VAE] Ep 770/8500 Train 63138.7363 | Val 66416.3477\n",
            "VAE Epoch: 770/8500 \tLoss: 63138.7363 \tRecon Loss: 61030.9596 \tKL Div: 69.8030\n",
            "[VAE] Ep 780/8500 Train 63042.5273 | Val 66323.9336\n",
            "   ↪︎ New best val loss 66323.9336  (checkpoint)\n",
            "VAE Epoch: 780/8500 \tLoss: 63042.5273 \tRecon Loss: 60983.4206 \tKL Div: 67.3170\n",
            "   ↪︎ New best val loss 66134.0840  (checkpoint)\n",
            "[VAE] Ep 790/8500 Train 63096.8145 | Val 66714.5703\n",
            "VAE Epoch: 790/8500 \tLoss: 63096.8145 \tRecon Loss: 60992.7982 \tKL Div: 67.9144\n",
            "[VAE] Ep 800/8500 Train 62796.2116 | Val 66370.1641\n",
            "VAE Epoch: 800/8500 \tLoss: 62796.2116 \tRecon Loss: 60686.3112 \tKL Div: 67.2531\n",
            "   ↪︎ New best val loss 66050.2090  (checkpoint)\n",
            "[VAE] Ep 810/8500 Train 62579.9974 | Val 66117.9707\n",
            "VAE Epoch: 810/8500 \tLoss: 62579.9974 \tRecon Loss: 60455.1133 \tKL Div: 66.8945\n",
            "[VAE] Ep 820/8500 Train 62536.0905 | Val 66089.9492\n",
            "VAE Epoch: 820/8500 \tLoss: 62536.0905 \tRecon Loss: 60386.7090 \tKL Div: 66.8405\n",
            "   ↪︎ New best val loss 66030.0469  (checkpoint)\n",
            "   ↪︎ New best val loss 66015.2168  (checkpoint)\n",
            "[VAE] Ep 830/8500 Train 62686.2331 | Val 65897.2227\n",
            "   ↪︎ New best val loss 65897.2227  (checkpoint)\n",
            "VAE Epoch: 830/8500 \tLoss: 62686.2331 \tRecon Loss: 60524.2103 \tKL Div: 66.4236\n",
            "[VAE] Ep 840/8500 Train 63034.9173 | Val 66288.2070\n",
            "VAE Epoch: 840/8500 \tLoss: 63034.9173 \tRecon Loss: 60835.1953 \tKL Div: 66.7773\n",
            "   ↪︎ New best val loss 65862.9766  (checkpoint)\n",
            "[VAE] Ep 850/8500 Train 62901.6283 | Val 65896.8984\n",
            "VAE Epoch: 850/8500 \tLoss: 62901.6283 \tRecon Loss: 60691.4714 \tKL Div: 66.3047\n",
            "   ↪︎ New best val loss 65783.3145  (checkpoint)\n",
            "   ↪︎ New best val loss 65770.9590  (checkpoint)\n",
            "[VAE] Ep 860/8500 Train 62701.4896 | Val 65760.3223\n",
            "   ↪︎ New best val loss 65760.3223  (checkpoint)\n",
            "VAE Epoch: 860/8500 \tLoss: 62701.4896 \tRecon Loss: 60499.7129 \tKL Div: 65.2852\n",
            "   ↪︎ New best val loss 65743.6836  (checkpoint)\n",
            "   ↪︎ New best val loss 65712.3203  (checkpoint)\n",
            "[VAE] Ep 870/8500 Train 62582.1055 | Val 65764.0938\n",
            "VAE Epoch: 870/8500 \tLoss: 62582.1055 \tRecon Loss: 60365.9727 \tKL Div: 64.9556\n",
            "   ↪︎ New best val loss 65682.0996  (checkpoint)\n",
            "[VAE] Ep 880/8500 Train 62949.6758 | Val 65854.8086\n",
            "VAE Epoch: 880/8500 \tLoss: 62949.6758 \tRecon Loss: 60715.0579 \tKL Div: 64.7531\n",
            "   ↪︎ New best val loss 65539.8223  (checkpoint)\n",
            "[VAE] Ep 890/8500 Train 62483.2715 | Val 65511.4824\n",
            "   ↪︎ New best val loss 65511.4824  (checkpoint)\n",
            "VAE Epoch: 890/8500 \tLoss: 62483.2715 \tRecon Loss: 60232.0547 \tKL Div: 64.5012\n",
            "   ↪︎ New best val loss 65420.8203  (checkpoint)\n",
            "[VAE] Ep 900/8500 Train 62990.7207 | Val 65634.1191\n",
            "VAE Epoch: 900/8500 \tLoss: 62990.7207 \tRecon Loss: 60739.9694 \tKL Div: 63.7713\n",
            "   ↪︎ New best val loss 65396.7832  (checkpoint)\n",
            "   ↪︎ New best val loss 65322.6055  (checkpoint)\n",
            "[VAE] Ep 910/8500 Train 62917.7240 | Val 65611.1758\n",
            "VAE Epoch: 910/8500 \tLoss: 62917.7240 \tRecon Loss: 60649.7181 \tKL Div: 63.5540\n",
            "   ↪︎ New best val loss 65229.5098  (checkpoint)\n",
            "   ↪︎ New best val loss 65198.9062  (checkpoint)\n",
            "   ↪︎ New best val loss 65114.9590  (checkpoint)\n",
            "[VAE] Ep 920/8500 Train 62659.6126 | Val 65186.6191\n",
            "VAE Epoch: 920/8500 \tLoss: 62659.6126 \tRecon Loss: 60375.7812 \tKL Div: 63.3019\n",
            "[VAE] Ep 930/8500 Train 62394.2402 | Val 65228.5371\n",
            "VAE Epoch: 930/8500 \tLoss: 62394.2402 \tRecon Loss: 60097.9792 \tKL Div: 62.9620\n",
            "   ↪︎ New best val loss 65071.1406  (checkpoint)\n",
            "[VAE] Ep 940/8500 Train 62510.4147 | Val 65357.9297\n",
            "VAE Epoch: 940/8500 \tLoss: 62510.4147 \tRecon Loss: 60246.7109 \tKL Div: 61.4090\n",
            "   ↪︎ New best val loss 65030.2422  (checkpoint)\n",
            "   ↪︎ New best val loss 64976.4531  (checkpoint)\n",
            "[VAE] Ep 950/8500 Train 62593.3796 | Val 65084.8164\n",
            "VAE Epoch: 950/8500 \tLoss: 62593.3796 \tRecon Loss: 60298.4076 \tKL Div: 61.6019\n",
            "   ↪︎ New best val loss 64936.4219  (checkpoint)\n",
            "   ↪︎ New best val loss 64917.3535  (checkpoint)\n",
            "   ↪︎ New best val loss 64883.0410  (checkpoint)\n",
            "[VAE] Ep 960/8500 Train 62355.4674 | Val 64905.5566\n",
            "VAE Epoch: 960/8500 \tLoss: 62355.4674 \tRecon Loss: 60011.2812 \tKL Div: 62.2675\n",
            "   ↪︎ New best val loss 64808.5645  (checkpoint)\n",
            "[VAE] Ep 970/8500 Train 62490.0560 | Val 65113.1445\n",
            "VAE Epoch: 970/8500 \tLoss: 62490.0560 \tRecon Loss: 60166.3665 \tKL Div: 61.0867\n",
            "[VAE] Ep 980/8500 Train 62197.0599 | Val 64834.5352\n",
            "VAE Epoch: 980/8500 \tLoss: 62197.0599 \tRecon Loss: 59867.2031 \tKL Div: 60.6238\n",
            "   ↪︎ New best val loss 64773.1367  (checkpoint)\n",
            "   ↪︎ New best val loss 64748.3789  (checkpoint)\n",
            "[VAE] Ep 990/8500 Train 62293.9121 | Val 64858.1133\n",
            "VAE Epoch: 990/8500 \tLoss: 62293.9121 \tRecon Loss: 59970.9915 \tKL Div: 59.8328\n",
            "   ↪︎ New best val loss 64695.1816  (checkpoint)\n",
            "[VAE] Ep 1000/8500 Train 62246.5885 | Val 65027.1758\n",
            "VAE Epoch: 1000/8500 \tLoss: 62246.5885 \tRecon Loss: 59891.8151 \tKL Div: 60.0467\n",
            "   ↪︎ New best val loss 64682.0156  (checkpoint)\n",
            "   ↪︎ New best val loss 64634.2188  (checkpoint)\n",
            "   ↪︎ New best val loss 64541.2578  (checkpoint)\n",
            "[VAE] Ep 1010/8500 Train 62324.7630 | Val 64721.5977\n",
            "VAE Epoch: 1010/8500 \tLoss: 62324.7630 \tRecon Loss: 59957.8203 \tKL Div: 59.7594\n",
            "   ↪︎ New best val loss 64518.4238  (checkpoint)\n",
            "   ↪︎ New best val loss 64394.6543  (checkpoint)\n",
            "[VAE] Ep 1020/8500 Train 62052.5488 | Val 64673.7988\n",
            "VAE Epoch: 1020/8500 \tLoss: 62052.5488 \tRecon Loss: 59653.6829 \tKL Div: 59.9717\n",
            "[VAE] Ep 1030/8500 Train 62239.9987 | Val 64678.2070\n",
            "VAE Epoch: 1030/8500 \tLoss: 62239.9987 \tRecon Loss: 59857.6777 \tKL Div: 58.9798\n",
            "   ↪︎ New best val loss 64260.6895  (checkpoint)\n",
            "[VAE] Ep 1040/8500 Train 62334.4010 | Val 64465.8086\n",
            "VAE Epoch: 1040/8500 \tLoss: 62334.4010 \tRecon Loss: 59931.5553 \tKL Div: 58.9159\n",
            "   ↪︎ New best val loss 64258.9785  (checkpoint)\n",
            "[VAE] Ep 1050/8500 Train 61910.5638 | Val 64502.4590\n",
            "VAE Epoch: 1050/8500 \tLoss: 61910.5638 \tRecon Loss: 59507.1628 \tKL Div: 58.3683\n",
            "[VAE] Ep 1060/8500 Train 62434.3620 | Val 64229.8613\n",
            "   ↪︎ New best val loss 64229.8613  (checkpoint)\n",
            "VAE Epoch: 1060/8500 \tLoss: 62434.3620 \tRecon Loss: 59986.1823 \tKL Div: 58.8949\n",
            "   ↪︎ New best val loss 64171.9297  (checkpoint)\n",
            "[VAE] Ep 1070/8500 Train 62125.6022 | Val 64292.7676\n",
            "VAE Epoch: 1070/8500 \tLoss: 62125.6022 \tRecon Loss: 59704.1133 \tKL Div: 57.7084\n",
            "   ↪︎ New best val loss 64090.8164  (checkpoint)\n",
            "   ↪︎ New best val loss 64068.2266  (checkpoint)\n",
            "[VAE] Ep 1080/8500 Train 62064.6048 | Val 64188.9570\n",
            "VAE Epoch: 1080/8500 \tLoss: 62064.6048 \tRecon Loss: 59625.8008 \tKL Div: 57.5829\n",
            "[VAE] Ep 1090/8500 Train 62070.2617 | Val 64154.1797\n",
            "VAE Epoch: 1090/8500 \tLoss: 62070.2617 \tRecon Loss: 59628.8607 \tKL Div: 57.1154\n",
            "   ↪︎ New best val loss 63974.7637  (checkpoint)\n",
            "[VAE] Ep 1100/8500 Train 61858.0143 | Val 64095.4199\n",
            "VAE Epoch: 1100/8500 \tLoss: 61858.0143 \tRecon Loss: 59447.2513 \tKL Div: 55.8859\n",
            "   ↪︎ New best val loss 63930.4824  (checkpoint)\n",
            "[VAE] Ep 1110/8500 Train 61893.1576 | Val 64039.3223\n",
            "VAE Epoch: 1110/8500 \tLoss: 61893.1576 \tRecon Loss: 59431.9642 \tKL Div: 56.5409\n",
            "   ↪︎ New best val loss 63810.1348  (checkpoint)\n",
            "[VAE] Ep 1120/8500 Train 62070.2760 | Val 63772.8633\n",
            "   ↪︎ New best val loss 63772.8633  (checkpoint)\n",
            "VAE Epoch: 1120/8500 \tLoss: 62070.2760 \tRecon Loss: 59651.1634 \tKL Div: 55.0780\n",
            "[VAE] Ep 1130/8500 Train 62083.4277 | Val 64076.5723\n",
            "VAE Epoch: 1130/8500 \tLoss: 62083.4277 \tRecon Loss: 59618.6823 \tKL Div: 55.6204\n",
            "   ↪︎ New best val loss 63729.4004  (checkpoint)\n",
            "[VAE] Ep 1140/8500 Train 61889.7155 | Val 63630.6641\n",
            "   ↪︎ New best val loss 63630.6641  (checkpoint)\n",
            "VAE Epoch: 1140/8500 \tLoss: 61889.7155 \tRecon Loss: 59403.4460 \tKL Div: 55.6139\n",
            "[VAE] Ep 1150/8500 Train 61699.6250 | Val 63678.5898\n",
            "VAE Epoch: 1150/8500 \tLoss: 61699.6250 \tRecon Loss: 59228.6562 \tKL Div: 54.7910\n",
            "   ↪︎ New best val loss 63598.9297  (checkpoint)\n",
            "   ↪︎ New best val loss 63596.1230  (checkpoint)\n",
            "   ↪︎ New best val loss 63569.0703  (checkpoint)\n",
            "   ↪︎ New best val loss 63550.6484  (checkpoint)\n",
            "[VAE] Ep 1160/8500 Train 61692.3555 | Val 63760.8848\n",
            "VAE Epoch: 1160/8500 \tLoss: 61692.3555 \tRecon Loss: 59216.7181 \tKL Div: 54.4214\n",
            "   ↪︎ New best val loss 63512.2930  (checkpoint)\n",
            "[VAE] Ep 1170/8500 Train 61916.8229 | Val 63607.5000\n",
            "VAE Epoch: 1170/8500 \tLoss: 61916.8229 \tRecon Loss: 59425.6380 \tKL Div: 54.2950\n",
            "[VAE] Ep 1180/8500 Train 61850.5573 | Val 63530.8262\n",
            "VAE Epoch: 1180/8500 \tLoss: 61850.5573 \tRecon Loss: 59324.7552 \tKL Div: 54.5830\n",
            "   ↪︎ New best val loss 63372.3203  (checkpoint)\n",
            "[VAE] Ep 1190/8500 Train 61911.2461 | Val 63380.1641\n",
            "VAE Epoch: 1190/8500 \tLoss: 61911.2461 \tRecon Loss: 59435.0540 \tKL Div: 53.0613\n",
            "   ↪︎ New best val loss 63370.2207  (checkpoint)\n",
            "   ↪︎ New best val loss 63346.1855  (checkpoint)\n",
            "   ↪︎ New best val loss 63309.5117  (checkpoint)\n",
            "[VAE] Ep 1200/8500 Train 61526.4336 | Val 63421.9219\n",
            "VAE Epoch: 1200/8500 \tLoss: 61526.4336 \tRecon Loss: 59012.8379 \tKL Div: 53.4139\n",
            "   ↪︎ New best val loss 63223.4746  (checkpoint)\n",
            "   ↪︎ New best val loss 63142.7344  (checkpoint)\n",
            "[VAE] Ep 1210/8500 Train 62046.3991 | Val 63192.6895\n",
            "VAE Epoch: 1210/8500 \tLoss: 62046.3991 \tRecon Loss: 59500.6439 \tKL Div: 53.6502\n",
            "[VAE] Ep 1220/8500 Train 61730.0293 | Val 63502.7344\n",
            "VAE Epoch: 1220/8500 \tLoss: 61730.0293 \tRecon Loss: 59184.6152 \tKL Div: 53.2033\n",
            "   ↪︎ New best val loss 63142.0918  (checkpoint)\n",
            "[VAE] Ep 1230/8500 Train 61637.3053 | Val 63158.8633\n",
            "VAE Epoch: 1230/8500 \tLoss: 61637.3053 \tRecon Loss: 59109.4447 \tKL Div: 52.4069\n",
            "   ↪︎ New best val loss 62996.3301  (checkpoint)\n",
            "[VAE] Ep 1240/8500 Train 61758.6296 | Val 63277.7285\n",
            "VAE Epoch: 1240/8500 \tLoss: 61758.6296 \tRecon Loss: 59193.6270 \tKL Div: 52.7480\n",
            "   ↪︎ New best val loss 62960.6914  (checkpoint)\n",
            "[VAE] Ep 1250/8500 Train 61445.3704 | Val 63078.9727\n",
            "VAE Epoch: 1250/8500 \tLoss: 61445.3704 \tRecon Loss: 58912.4948 \tKL Div: 51.6707\n",
            "   ↪︎ New best val loss 62944.7637  (checkpoint)\n",
            "[VAE] Ep 1260/8500 Train 61913.2624 | Val 62985.7676\n",
            "VAE Epoch: 1260/8500 \tLoss: 61913.2624 \tRecon Loss: 59345.6660 \tKL Div: 51.9633\n",
            "[VAE] Ep 1270/8500 Train 61390.7038 | Val 63046.7891\n",
            "VAE Epoch: 1270/8500 \tLoss: 61390.7038 \tRecon Loss: 58813.0371 \tKL Div: 51.7563\n",
            "   ↪︎ New best val loss 62907.1152  (checkpoint)\n",
            "   ↪︎ New best val loss 62886.8789  (checkpoint)\n",
            "[VAE] Ep 1280/8500 Train 61710.6589 | Val 63198.5000\n",
            "VAE Epoch: 1280/8500 \tLoss: 61710.6589 \tRecon Loss: 59169.2526 \tKL Div: 50.6296\n",
            "   ↪︎ New best val loss 62848.3594  (checkpoint)\n",
            "[VAE] Ep 1290/8500 Train 61674.9323 | Val 63019.9414\n",
            "VAE Epoch: 1290/8500 \tLoss: 61674.9323 \tRecon Loss: 59078.1855 \tKL Div: 51.3310\n",
            "   ↪︎ New best val loss 62774.6738  (checkpoint)\n",
            "   ↪︎ New best val loss 62685.4590  (checkpoint)\n",
            "[VAE] Ep 1300/8500 Train 61721.5111 | Val 62954.5234\n",
            "VAE Epoch: 1300/8500 \tLoss: 61721.5111 \tRecon Loss: 59113.3783 \tKL Div: 51.1595\n",
            "[VAE] Ep 1310/8500 Train 61293.6784 | Val 62768.9805\n",
            "VAE Epoch: 1310/8500 \tLoss: 61293.6784 \tRecon Loss: 58688.9733 \tKL Div: 50.7023\n",
            "   ↪︎ New best val loss 62681.4180  (checkpoint)\n",
            "[VAE] Ep 1320/8500 Train 61717.0280 | Val 62938.1719\n",
            "VAE Epoch: 1320/8500 \tLoss: 61717.0280 \tRecon Loss: 59084.0456 \tKL Div: 50.8644\n",
            "   ↪︎ New best val loss 62622.2734  (checkpoint)\n",
            "[VAE] Ep 1330/8500 Train 61610.0267 | Val 63017.2871\n",
            "VAE Epoch: 1330/8500 \tLoss: 61610.0267 \tRecon Loss: 59029.9329 \tKL Div: 49.4680\n",
            "[VAE] Ep 1340/8500 Train 61731.0527 | Val 63302.2871\n",
            "VAE Epoch: 1340/8500 \tLoss: 61731.0527 \tRecon Loss: 59110.4603 \tKL Div: 49.8695\n",
            "   ↪︎ New best val loss 62611.0000  (checkpoint)\n",
            "[VAE] Ep 1350/8500 Train 61615.5182 | Val 62689.2207\n",
            "VAE Epoch: 1350/8500 \tLoss: 61615.5182 \tRecon Loss: 58965.1178 \tKL Div: 50.0631\n",
            "   ↪︎ New best val loss 62539.2500  (checkpoint)\n",
            "   ↪︎ New best val loss 62443.2637  (checkpoint)\n",
            "[VAE] Ep 1360/8500 Train 61240.7539 | Val 62522.0664\n",
            "VAE Epoch: 1360/8500 \tLoss: 61240.7539 \tRecon Loss: 58596.6641 \tKL Div: 49.5767\n",
            "   ↪︎ New best val loss 62421.8066  (checkpoint)\n",
            "[VAE] Ep 1370/8500 Train 61347.8783 | Val 62690.7070\n",
            "VAE Epoch: 1370/8500 \tLoss: 61347.8783 \tRecon Loss: 58719.8906 \tKL Div: 48.9151\n",
            "   ↪︎ New best val loss 62282.1328  (checkpoint)\n",
            "[VAE] Ep 1380/8500 Train 61312.6302 | Val 62600.9980\n",
            "VAE Epoch: 1380/8500 \tLoss: 61312.6302 \tRecon Loss: 58649.0801 \tKL Div: 49.2178\n",
            "[VAE] Ep 1390/8500 Train 61612.2956 | Val 62431.1719\n",
            "VAE Epoch: 1390/8500 \tLoss: 61612.2956 \tRecon Loss: 58941.8451 \tKL Div: 48.9903\n",
            "   ↪︎ New best val loss 62268.5547  (checkpoint)\n",
            "   ↪︎ New best val loss 62236.1875  (checkpoint)\n",
            "[VAE] Ep 1400/8500 Train 61235.4785 | Val 62293.3262\n",
            "VAE Epoch: 1400/8500 \tLoss: 61235.4785 \tRecon Loss: 58573.1139 \tKL Div: 48.4931\n",
            "[VAE] Ep 1410/8500 Train 61409.4629 | Val 62250.7051\n",
            "VAE Epoch: 1410/8500 \tLoss: 61409.4629 \tRecon Loss: 58729.7090 \tKL Div: 48.4636\n",
            "   ↪︎ New best val loss 62146.1133  (checkpoint)\n",
            "[VAE] Ep 1420/8500 Train 61282.2578 | Val 62283.0996\n",
            "VAE Epoch: 1420/8500 \tLoss: 61282.2578 \tRecon Loss: 58584.0625 \tKL Div: 48.4535\n",
            "[VAE] Ep 1430/8500 Train 61055.8835 | Val 62319.3184\n",
            "VAE Epoch: 1430/8500 \tLoss: 61055.8835 \tRecon Loss: 58319.6042 \tKL Div: 48.7938\n",
            "   ↪︎ New best val loss 62076.5645  (checkpoint)\n",
            "[VAE] Ep 1440/8500 Train 61270.3197 | Val 62137.0781\n",
            "VAE Epoch: 1440/8500 \tLoss: 61270.3197 \tRecon Loss: 58523.0918 \tKL Div: 48.6488\n",
            "   ↪︎ New best val loss 62073.3750  (checkpoint)\n",
            "[VAE] Ep 1450/8500 Train 61184.9115 | Val 62234.6758\n",
            "VAE Epoch: 1450/8500 \tLoss: 61184.9115 \tRecon Loss: 58435.7259 \tKL Div: 48.3478\n",
            "[VAE] Ep 1460/8500 Train 61129.9108 | Val 62703.0879\n",
            "VAE Epoch: 1460/8500 \tLoss: 61129.9108 \tRecon Loss: 58398.2773 \tKL Div: 47.7100\n",
            "[VAE] Ep 1470/8500 Train 61447.0488 | Val 62146.4199\n",
            "VAE Epoch: 1470/8500 \tLoss: 61447.0488 \tRecon Loss: 58733.2383 \tKL Div: 47.0763\n",
            "   ↪︎ New best val loss 62066.1016  (checkpoint)\n",
            "   ↪︎ New best val loss 61967.8613  (checkpoint)\n",
            "   ↪︎ New best val loss 61949.7305  (checkpoint)\n",
            "   ↪︎ New best val loss 61918.8066  (checkpoint)\n",
            "[VAE] Ep 1480/8500 Train 60948.8789 | Val 61953.4316\n",
            "VAE Epoch: 1480/8500 \tLoss: 60948.8789 \tRecon Loss: 58200.3991 \tKL Div: 47.3556\n",
            "   ↪︎ New best val loss 61864.3848  (checkpoint)\n",
            "[VAE] Ep 1490/8500 Train 61281.1100 | Val 62011.2969\n",
            "VAE Epoch: 1490/8500 \tLoss: 61281.1100 \tRecon Loss: 58521.3281 \tKL Div: 47.2312\n",
            "   ↪︎ New best val loss 61825.1660  (checkpoint)\n",
            "[VAE] Ep 1500/8500 Train 61077.3939 | Val 62013.7402\n",
            "VAE Epoch: 1500/8500 \tLoss: 61077.3939 \tRecon Loss: 58282.8783 \tKL Div: 47.5068\n",
            "   ↪︎ New best val loss 61794.5684  (checkpoint)\n",
            "[VAE] Ep 1510/8500 Train 61153.8411 | Val 62021.3379\n",
            "VAE Epoch: 1510/8500 \tLoss: 61153.8411 \tRecon Loss: 58388.2116 \tKL Div: 46.7044\n",
            "   ↪︎ New best val loss 61742.4707  (checkpoint)\n",
            "   ↪︎ New best val loss 61714.4121  (checkpoint)\n",
            "   ↪︎ New best val loss 61713.6504  (checkpoint)\n",
            "[VAE] Ep 1520/8500 Train 61223.2331 | Val 61791.5332\n",
            "VAE Epoch: 1520/8500 \tLoss: 61223.2331 \tRecon Loss: 58432.9316 \tKL Div: 46.8110\n",
            "[VAE] Ep 1530/8500 Train 61238.6413 | Val 62062.5508\n",
            "VAE Epoch: 1530/8500 \tLoss: 61238.6413 \tRecon Loss: 58451.2331 \tKL Div: 46.4568\n",
            "   ↪︎ New best val loss 61568.4199  (checkpoint)\n",
            "[VAE] Ep 1540/8500 Train 61011.3490 | Val 61783.8145\n",
            "VAE Epoch: 1540/8500 \tLoss: 61011.3490 \tRecon Loss: 58208.9922 \tKL Div: 46.4026\n",
            "[VAE] Ep 1550/8500 Train 61354.3529 | Val 61977.6465\n",
            "VAE Epoch: 1550/8500 \tLoss: 61354.3529 \tRecon Loss: 58521.2214 \tKL Div: 46.6096\n",
            "[VAE] Ep 1560/8500 Train 61183.4987 | Val 61742.0488\n",
            "VAE Epoch: 1560/8500 \tLoss: 61183.4987 \tRecon Loss: 58329.9759 \tKL Div: 46.6441\n",
            "[VAE] Ep 1570/8500 Train 61128.6628 | Val 61572.6094\n",
            "VAE Epoch: 1570/8500 \tLoss: 61128.6628 \tRecon Loss: 58312.0768 \tKL Div: 45.7471\n",
            "[VAE] Ep 1580/8500 Train 61121.6296 | Val 61551.4648\n",
            "   ↪︎ New best val loss 61551.4648  (checkpoint)\n",
            "VAE Epoch: 1580/8500 \tLoss: 61121.6296 \tRecon Loss: 58265.8809 \tKL Div: 46.0896\n",
            "[VAE] Ep 1590/8500 Train 61326.4349 | Val 62096.5078\n",
            "VAE Epoch: 1590/8500 \tLoss: 61326.4349 \tRecon Loss: 58468.5605 \tKL Div: 45.8338\n",
            "[VAE] Ep 1600/8500 Train 61224.9004 | Val 61653.0332\n",
            "VAE Epoch: 1600/8500 \tLoss: 61224.9004 \tRecon Loss: 58353.3529 \tKL Div: 45.7653\n",
            "   ↪︎ New best val loss 61517.9199  (checkpoint)\n",
            "   ↪︎ New best val loss 61440.8008  (checkpoint)\n",
            "[VAE] Ep 1610/8500 Train 61101.6621 | Val 61620.7109\n",
            "VAE Epoch: 1610/8500 \tLoss: 61101.6621 \tRecon Loss: 58238.0820 \tKL Div: 45.3548\n",
            "[VAE] Ep 1620/8500 Train 60992.5879 | Val 61432.3164\n",
            "   ↪︎ New best val loss 61432.3164  (checkpoint)\n",
            "VAE Epoch: 1620/8500 \tLoss: 60992.5879 \tRecon Loss: 58102.8503 \tKL Div: 45.4866\n",
            "[VAE] Ep 1630/8500 Train 61033.3151 | Val 61478.8242\n",
            "VAE Epoch: 1630/8500 \tLoss: 61033.3151 \tRecon Loss: 58149.7904 \tKL Div: 45.1104\n",
            "   ↪︎ New best val loss 61383.8262  (checkpoint)\n",
            "[VAE] Ep 1640/8500 Train 61110.5618 | Val 61505.4414\n",
            "VAE Epoch: 1640/8500 \tLoss: 61110.5618 \tRecon Loss: 58214.2161 \tKL Div: 45.0346\n",
            "[VAE] Ep 1650/8500 Train 61207.2435 | Val 61682.1426\n",
            "VAE Epoch: 1650/8500 \tLoss: 61207.2435 \tRecon Loss: 58290.6172 \tKL Div: 45.0751\n",
            "   ↪︎ New best val loss 61364.4570  (checkpoint)\n",
            "[VAE] Ep 1660/8500 Train 61034.2754 | Val 61494.5625\n",
            "VAE Epoch: 1660/8500 \tLoss: 61034.2754 \tRecon Loss: 58104.9551 \tKL Div: 44.9986\n",
            "[VAE] Ep 1670/8500 Train 60969.9674 | Val 61367.1016\n",
            "VAE Epoch: 1670/8500 \tLoss: 60969.9674 \tRecon Loss: 58029.0645 \tKL Div: 44.9060\n",
            "   ↪︎ New best val loss 61324.2285  (checkpoint)\n",
            "[VAE] Ep 1680/8500 Train 60899.5957 | Val 61502.7695\n",
            "VAE Epoch: 1680/8500 \tLoss: 60899.5957 \tRecon Loss: 57973.3125 \tKL Div: 44.4168\n",
            "   ↪︎ New best val loss 61316.4160  (checkpoint)\n",
            "[VAE] Ep 1690/8500 Train 60938.1673 | Val 61348.4316\n",
            "VAE Epoch: 1690/8500 \tLoss: 60938.1673 \tRecon Loss: 57991.0384 \tKL Div: 44.4685\n",
            "   ↪︎ New best val loss 61190.4199  (checkpoint)\n",
            "   ↪︎ New best val loss 61100.3535  (checkpoint)\n",
            "[VAE] Ep 1700/8500 Train 60975.5391 | Val 61241.4395\n",
            "VAE Epoch: 1700/8500 \tLoss: 60975.5391 \tRecon Loss: 58006.3333 \tKL Div: 44.5381\n",
            "[VAE] Ep 1710/8500 Train 61075.6484 | Val 61344.1973\n",
            "VAE Epoch: 1710/8500 \tLoss: 61075.6484 \tRecon Loss: 58091.4460 \tKL Div: 44.5013\n",
            "[VAE] Ep 1720/8500 Train 61157.7480 | Val 61331.5332\n",
            "VAE Epoch: 1720/8500 \tLoss: 61157.7480 \tRecon Loss: 58143.2741 \tKL Div: 44.6913\n",
            "[VAE] Ep 1730/8500 Train 61133.3893 | Val 61394.2656\n",
            "VAE Epoch: 1730/8500 \tLoss: 61133.3893 \tRecon Loss: 58148.3945 \tKL Div: 43.9985\n",
            "   ↪︎ New best val loss 61068.8867  (checkpoint)\n",
            "[VAE] Ep 1740/8500 Train 61057.4870 | Val 61215.8906\n",
            "VAE Epoch: 1740/8500 \tLoss: 61057.4870 \tRecon Loss: 58072.5957 \tKL Div: 43.7441\n",
            "   ↪︎ New best val loss 61053.3379  (checkpoint)\n",
            "   ↪︎ New best val loss 61029.6992  (checkpoint)\n",
            "   ↪︎ New best val loss 60991.8789  (checkpoint)\n",
            "[VAE] Ep 1750/8500 Train 60612.2220 | Val 61187.3809\n",
            "VAE Epoch: 1750/8500 \tLoss: 60612.2220 \tRecon Loss: 57622.9251 \tKL Div: 43.5583\n",
            "[VAE] Ep 1760/8500 Train 60746.5391 | Val 61068.2734\n",
            "VAE Epoch: 1760/8500 \tLoss: 60746.5391 \tRecon Loss: 57748.3991 \tKL Div: 43.4390\n",
            "[VAE] Ep 1770/8500 Train 61111.3529 | Val 61134.8379\n",
            "VAE Epoch: 1770/8500 \tLoss: 61111.3529 \tRecon Loss: 58110.4499 \tKL Div: 43.2333\n",
            "   ↪︎ New best val loss 60965.7754  (checkpoint)\n",
            "   ↪︎ New best val loss 60905.9004  (checkpoint)\n",
            "[VAE] Ep 1780/8500 Train 61027.0853 | Val 60901.2246\n",
            "   ↪︎ New best val loss 60901.2246  (checkpoint)\n",
            "VAE Epoch: 1780/8500 \tLoss: 61027.0853 \tRecon Loss: 57996.2383 \tKL Div: 43.4194\n",
            "   ↪︎ New best val loss 60890.4453  (checkpoint)\n",
            "[VAE] Ep 1790/8500 Train 60908.8841 | Val 61187.3672\n",
            "VAE Epoch: 1790/8500 \tLoss: 60908.8841 \tRecon Loss: 57840.6543 \tKL Div: 43.7094\n",
            "[VAE] Ep 1800/8500 Train 60907.9941 | Val 61079.6641\n",
            "VAE Epoch: 1800/8500 \tLoss: 60907.9941 \tRecon Loss: 57895.3991 \tKL Div: 42.6784\n",
            "   ↪︎ New best val loss 60880.8320  (checkpoint)\n",
            "[VAE] Ep 1810/8500 Train 60927.4193 | Val 60952.4219\n",
            "VAE Epoch: 1810/8500 \tLoss: 60927.4193 \tRecon Loss: 57896.4121 \tKL Div: 42.7020\n",
            "   ↪︎ New best val loss 60880.2617  (checkpoint)\n",
            "[VAE] Ep 1820/8500 Train 60726.9069 | Val 60961.6348\n",
            "VAE Epoch: 1820/8500 \tLoss: 60726.9069 \tRecon Loss: 57667.4297 \tKL Div: 42.8663\n",
            "   ↪︎ New best val loss 60870.1426  (checkpoint)\n",
            "   ↪︎ New best val loss 60860.3828  (checkpoint)\n",
            "   ↪︎ New best val loss 60820.9316  (checkpoint)\n",
            "[VAE] Ep 1830/8500 Train 60579.7969 | Val 60923.0703\n",
            "VAE Epoch: 1830/8500 \tLoss: 60579.7969 \tRecon Loss: 57531.5423 \tKL Div: 42.4757\n",
            "[VAE] Ep 1840/8500 Train 60892.6341 | Val 61105.6016\n",
            "VAE Epoch: 1840/8500 \tLoss: 60892.6341 \tRecon Loss: 57855.1061 \tKL Div: 42.0962\n",
            "   ↪︎ New best val loss 60785.5273  (checkpoint)\n",
            "   ↪︎ New best val loss 60694.6953  (checkpoint)\n",
            "[VAE] Ep 1850/8500 Train 60855.2624 | Val 60973.3027\n",
            "VAE Epoch: 1850/8500 \tLoss: 60855.2624 \tRecon Loss: 57787.6712 \tKL Div: 42.2830\n",
            "[VAE] Ep 1860/8500 Train 60664.4590 | Val 60919.3418\n",
            "VAE Epoch: 1860/8500 \tLoss: 60664.4590 \tRecon Loss: 57577.7591 \tKL Div: 42.3177\n",
            "[VAE] Ep 1870/8500 Train 60807.8730 | Val 60885.1562\n",
            "VAE Epoch: 1870/8500 \tLoss: 60807.8730 \tRecon Loss: 57718.9134 \tKL Div: 42.1222\n",
            "[VAE] Ep 1880/8500 Train 60813.5755 | Val 60783.9629\n",
            "VAE Epoch: 1880/8500 \tLoss: 60813.5755 \tRecon Loss: 57723.9974 \tKL Div: 41.9065\n",
            "   ↪︎ New best val loss 60648.1855  (checkpoint)\n",
            "   ↪︎ New best val loss 60644.2070  (checkpoint)\n",
            "[VAE] Ep 1890/8500 Train 60701.8047 | Val 60810.4297\n",
            "VAE Epoch: 1890/8500 \tLoss: 60701.8047 \tRecon Loss: 57597.2741 \tKL Div: 41.8865\n",
            "[VAE] Ep 1900/8500 Train 60779.3372 | Val 60752.6348\n",
            "VAE Epoch: 1900/8500 \tLoss: 60779.3372 \tRecon Loss: 57676.0964 \tKL Div: 41.6488\n",
            "   ↪︎ New best val loss 60614.8984  (checkpoint)\n",
            "[VAE] Ep 1910/8500 Train 61018.5944 | Val 60936.2832\n",
            "VAE Epoch: 1910/8500 \tLoss: 61018.5944 \tRecon Loss: 57891.0202 \tKL Div: 41.7556\n",
            "[VAE] Ep 1920/8500 Train 60740.5599 | Val 61007.1484\n",
            "VAE Epoch: 1920/8500 \tLoss: 60740.5599 \tRecon Loss: 57617.5807 \tKL Div: 41.4771\n",
            "   ↪︎ New best val loss 60598.1875  (checkpoint)\n",
            "   ↪︎ New best val loss 60558.0859  (checkpoint)\n",
            "[VAE] Ep 1930/8500 Train 60858.5482 | Val 60547.9590\n",
            "   ↪︎ New best val loss 60547.9590  (checkpoint)\n",
            "VAE Epoch: 1930/8500 \tLoss: 60858.5482 \tRecon Loss: 57684.2012 \tKL Div: 41.9409\n",
            "   ↪︎ New best val loss 60545.1699  (checkpoint)\n",
            "   ↪︎ New best val loss 60532.8164  (checkpoint)\n",
            "   ↪︎ New best val loss 60514.4238  (checkpoint)\n",
            "[VAE] Ep 1940/8500 Train 60987.6628 | Val 60687.7148\n",
            "VAE Epoch: 1940/8500 \tLoss: 60987.6628 \tRecon Loss: 57817.3685 \tKL Div: 41.6714\n",
            "[VAE] Ep 1950/8500 Train 60886.8001 | Val 60802.1934\n",
            "VAE Epoch: 1950/8500 \tLoss: 60886.8001 \tRecon Loss: 57720.3672 \tKL Div: 41.4072\n",
            "   ↪︎ New best val loss 60449.5625  (checkpoint)\n",
            "[VAE] Ep 1960/8500 Train 60954.8607 | Val 60796.8926\n",
            "VAE Epoch: 1960/8500 \tLoss: 60954.8607 \tRecon Loss: 57779.7624 \tKL Div: 41.3087\n",
            "[VAE] Ep 1970/8500 Train 60780.8704 | Val 60591.8789\n",
            "VAE Epoch: 1970/8500 \tLoss: 60780.8704 \tRecon Loss: 57585.2435 \tKL Div: 41.3647\n",
            "[VAE] Ep 1980/8500 Train 61050.4212 | Val 60712.1797\n",
            "VAE Epoch: 1980/8500 \tLoss: 61050.4212 \tRecon Loss: 57827.3398 \tKL Div: 41.5094\n",
            "   ↪︎ New best val loss 60443.6016  (checkpoint)\n",
            "[VAE] Ep 1990/8500 Train 60792.6790 | Val 60436.9902\n",
            "   ↪︎ New best val loss 60436.9902  (checkpoint)\n",
            "VAE Epoch: 1990/8500 \tLoss: 60792.6790 \tRecon Loss: 57581.9095 \tKL Div: 41.1430\n",
            "   ↪︎ New best val loss 60392.0215  (checkpoint)\n",
            "[VAE] Ep 2000/8500 Train 60842.1432 | Val 60579.0527\n",
            "VAE Epoch: 2000/8500 \tLoss: 60842.1432 \tRecon Loss: 57630.6693 \tKL Div: 40.9463\n",
            "   ↪︎ New best val loss 60384.6270  (checkpoint)\n",
            "[VAE] Ep 2010/8500 Train 60773.5384 | Val 60559.3926\n",
            "VAE Epoch: 2010/8500 \tLoss: 60773.5384 \tRecon Loss: 57528.6777 \tKL Div: 41.1661\n",
            "   ↪︎ New best val loss 60374.3633  (checkpoint)\n",
            "   ↪︎ New best val loss 60366.0938  (checkpoint)\n",
            "[VAE] Ep 2020/8500 Train 60620.1400 | Val 60472.4004\n",
            "VAE Epoch: 2020/8500 \tLoss: 60620.1400 \tRecon Loss: 57358.0957 \tKL Div: 41.1793\n",
            "[VAE] Ep 2030/8500 Train 60758.5879 | Val 60614.8164\n",
            "VAE Epoch: 2030/8500 \tLoss: 60758.5879 \tRecon Loss: 57449.6790 \tKL Div: 41.5651\n",
            "   ↪︎ New best val loss 60241.2695  (checkpoint)\n",
            "[VAE] Ep 2040/8500 Train 60856.9303 | Val 60427.8984\n",
            "VAE Epoch: 2040/8500 \tLoss: 60856.9303 \tRecon Loss: 57582.8913 \tKL Div: 40.9255\n",
            "[VAE] Ep 2050/8500 Train 60842.7474 | Val 60493.7461\n",
            "VAE Epoch: 2050/8500 \tLoss: 60842.7474 \tRecon Loss: 57531.0137 \tKL Div: 41.1947\n",
            "[VAE] Ep 2060/8500 Train 60900.1777 | Val 60391.2129\n",
            "VAE Epoch: 2060/8500 \tLoss: 60900.1777 \tRecon Loss: 57647.6094 \tKL Div: 40.2624\n",
            "   ↪︎ New best val loss 60227.4297  (checkpoint)\n",
            "[VAE] Ep 2070/8500 Train 60705.8574 | Val 60441.7734\n",
            "VAE Epoch: 2070/8500 \tLoss: 60705.8574 \tRecon Loss: 57413.4134 \tKL Div: 40.5591\n",
            "   ↪︎ New best val loss 60224.4453  (checkpoint)\n",
            "[VAE] Ep 2080/8500 Train 60733.6139 | Val 60391.2422\n",
            "VAE Epoch: 2080/8500 \tLoss: 60733.6139 \tRecon Loss: 57414.8132 \tKL Div: 40.6872\n",
            "[VAE] Ep 2090/8500 Train 60813.3333 | Val 60306.8574\n",
            "VAE Epoch: 2090/8500 \tLoss: 60813.3333 \tRecon Loss: 57458.2214 \tKL Div: 40.9356\n",
            "   ↪︎ New best val loss 60167.4746  (checkpoint)\n",
            "[VAE] Ep 2100/8500 Train 60991.3385 | Val 60227.0762\n",
            "VAE Epoch: 2100/8500 \tLoss: 60991.3385 \tRecon Loss: 57689.9316 \tKL Div: 40.0885\n",
            "[VAE] Ep 2110/8500 Train 60764.2533 | Val 60472.6875\n",
            "VAE Epoch: 2110/8500 \tLoss: 60764.2533 \tRecon Loss: 57437.1146 \tKL Div: 40.2095\n",
            "[VAE] Ep 2120/8500 Train 60810.3398 | Val 60742.0156\n",
            "VAE Epoch: 2120/8500 \tLoss: 60810.3398 \tRecon Loss: 57442.3932 \tKL Div: 40.5107\n",
            "[VAE] Ep 2130/8500 Train 60819.3008 | Val 60102.4453\n",
            "   ↪︎ New best val loss 60102.4453  (checkpoint)\n",
            "VAE Epoch: 2130/8500 \tLoss: 60819.3008 \tRecon Loss: 57444.3828 \tKL Div: 40.4039\n",
            "[VAE] Ep 2140/8500 Train 60747.6927 | Val 60276.1484\n",
            "VAE Epoch: 2140/8500 \tLoss: 60747.6927 \tRecon Loss: 57373.5078 \tKL Div: 40.2064\n",
            "   ↪︎ New best val loss 60085.5840  (checkpoint)\n",
            "[VAE] Ep 2150/8500 Train 60786.5085 | Val 60155.2578\n",
            "VAE Epoch: 2150/8500 \tLoss: 60786.5085 \tRecon Loss: 57393.8210 \tKL Div: 40.2389\n",
            "   ↪︎ New best val loss 60085.1035  (checkpoint)\n",
            "   ↪︎ New best val loss 60043.8477  (checkpoint)\n",
            "[VAE] Ep 2160/8500 Train 60857.2272 | Val 60249.2461\n",
            "VAE Epoch: 2160/8500 \tLoss: 60857.2272 \tRecon Loss: 57470.9831 \tKL Div: 39.9765\n",
            "   ↪︎ New best val loss 60015.6875  (checkpoint)\n",
            "   ↪︎ New best val loss 60014.3105  (checkpoint)\n",
            "[VAE] Ep 2170/8500 Train 60781.4538 | Val 60148.9844\n",
            "VAE Epoch: 2170/8500 \tLoss: 60781.4538 \tRecon Loss: 57398.9557 \tKL Div: 39.7482\n",
            "[VAE] Ep 2180/8500 Train 61127.2546 | Val 60589.6191\n",
            "VAE Epoch: 2180/8500 \tLoss: 61127.2546 \tRecon Loss: 57754.4759 \tKL Div: 39.4522\n",
            "   ↪︎ New best val loss 59997.9902  (checkpoint)\n",
            "[VAE] Ep 2190/8500 Train 60902.6914 | Val 61004.0352\n",
            "VAE Epoch: 2190/8500 \tLoss: 60902.6914 \tRecon Loss: 57508.3809 \tKL Div: 39.5228\n",
            "[VAE] Ep 2200/8500 Train 61024.4290 | Val 60342.5312\n",
            "VAE Epoch: 2200/8500 \tLoss: 61024.4290 \tRecon Loss: 57613.2044 \tKL Div: 39.5392\n",
            "[VAE] Ep 2210/8500 Train 60648.4310 | Val 60161.0020\n",
            "VAE Epoch: 2210/8500 \tLoss: 60648.4310 \tRecon Loss: 57259.5977 \tKL Div: 39.1019\n",
            "[VAE] Ep 2220/8500 Train 60679.4525 | Val 60048.7695\n",
            "VAE Epoch: 2220/8500 \tLoss: 60679.4525 \tRecon Loss: 57283.3685 \tKL Div: 39.0091\n",
            "   ↪︎ New best val loss 59939.5605  (checkpoint)\n",
            "   ↪︎ New best val loss 59910.5742  (checkpoint)\n",
            "[VAE] Ep 2230/8500 Train 60677.3099 | Val 60063.5371\n",
            "VAE Epoch: 2230/8500 \tLoss: 60677.3099 \tRecon Loss: 57213.3665 \tKL Div: 39.6101\n",
            "[VAE] Ep 2240/8500 Train 60748.4922 | Val 59889.5234\n",
            "   ↪︎ New best val loss 59889.5234  (checkpoint)\n",
            "VAE Epoch: 2240/8500 \tLoss: 60748.4922 \tRecon Loss: 57299.4642 \tKL Div: 39.2635\n",
            "[VAE] Ep 2250/8500 Train 60634.2826 | Val 59881.4160\n",
            "   ↪︎ New best val loss 59881.4160  (checkpoint)\n",
            "VAE Epoch: 2250/8500 \tLoss: 60634.2826 \tRecon Loss: 57216.2109 \tKL Div: 38.7381\n",
            "[VAE] Ep 2260/8500 Train 60884.9147 | Val 60031.2422\n",
            "VAE Epoch: 2260/8500 \tLoss: 60884.9147 \tRecon Loss: 57395.3529 \tKL Div: 39.3734\n",
            "[VAE] Ep 2270/8500 Train 60573.2520 | Val 59897.3691\n",
            "VAE Epoch: 2270/8500 \tLoss: 60573.2520 \tRecon Loss: 57134.6165 \tKL Div: 38.6278\n",
            "   ↪︎ New best val loss 59865.3184  (checkpoint)\n",
            "   ↪︎ New best val loss 59808.3184  (checkpoint)\n",
            "[VAE] Ep 2280/8500 Train 60699.5833 | Val 59963.2188\n",
            "VAE Epoch: 2280/8500 \tLoss: 60699.5833 \tRecon Loss: 57225.0599 \tKL Div: 38.8598\n",
            "   ↪︎ New best val loss 59711.3906  (checkpoint)\n",
            "[VAE] Ep 2290/8500 Train 60653.7643 | Val 59890.3301\n",
            "VAE Epoch: 2290/8500 \tLoss: 60653.7643 \tRecon Loss: 57172.5970 \tKL Div: 38.7641\n",
            "[VAE] Ep 2300/8500 Train 60616.1439 | Val 59849.9062\n",
            "VAE Epoch: 2300/8500 \tLoss: 60616.1439 \tRecon Loss: 57124.2910 \tKL Div: 38.7140\n",
            "[VAE] Ep 2310/8500 Train 60714.3509 | Val 59814.5215\n",
            "VAE Epoch: 2310/8500 \tLoss: 60714.3509 \tRecon Loss: 57180.4609 \tKL Div: 39.0105\n",
            "[VAE] Ep 2320/8500 Train 60484.7643 | Val 59797.1836\n",
            "VAE Epoch: 2320/8500 \tLoss: 60484.7643 \tRecon Loss: 56937.9596 \tKL Div: 38.9843\n",
            "[VAE] Ep 2330/8500 Train 60695.9629 | Val 59810.9297\n",
            "VAE Epoch: 2330/8500 \tLoss: 60695.9629 \tRecon Loss: 57208.4186 \tKL Div: 38.1684\n",
            "[VAE] Ep 2340/8500 Train 60821.7181 | Val 59904.8105\n",
            "VAE Epoch: 2340/8500 \tLoss: 60821.7181 \tRecon Loss: 57264.6055 \tKL Div: 38.7634\n",
            "   ↪︎ New best val loss 59664.8652  (checkpoint)\n",
            "[VAE] Ep 2350/8500 Train 60446.1510 | Val 59870.2812\n",
            "VAE Epoch: 2350/8500 \tLoss: 60446.1510 \tRecon Loss: 56927.4635 \tKL Div: 38.1815\n",
            "[VAE] Ep 2360/8500 Train 60880.2826 | Val 59763.5332\n",
            "VAE Epoch: 2360/8500 \tLoss: 60880.2826 \tRecon Loss: 57315.5404 \tKL Div: 38.5173\n",
            "[VAE] Ep 2370/8500 Train 60724.7500 | Val 59866.5117\n",
            "VAE Epoch: 2370/8500 \tLoss: 60724.7500 \tRecon Loss: 57166.0482 \tKL Div: 38.2898\n",
            "[VAE] Ep 2380/8500 Train 61017.1654 | Val 61128.3301\n",
            "VAE Epoch: 2380/8500 \tLoss: 61017.1654 \tRecon Loss: 57435.0938 \tKL Div: 38.3793\n",
            "[VAE] Ep 2390/8500 Train 60658.1367 | Val 59684.6758\n",
            "VAE Epoch: 2390/8500 \tLoss: 60658.1367 \tRecon Loss: 57079.0332 \tKL Div: 38.1871\n",
            "   ↪︎ New best val loss 59658.7266  (checkpoint)\n",
            "   ↪︎ New best val loss 59581.7656  (checkpoint)\n",
            "[VAE] Ep 2400/8500 Train 60595.8783 | Val 59652.4023\n",
            "VAE Epoch: 2400/8500 \tLoss: 60595.8783 \tRecon Loss: 57018.0716 \tKL Div: 38.0142\n",
            "[VAE] Ep 2410/8500 Train 60569.9980 | Val 59732.2324\n",
            "VAE Epoch: 2410/8500 \tLoss: 60569.9980 \tRecon Loss: 56958.9629 \tKL Div: 38.2080\n",
            "[VAE] Ep 2420/8500 Train 60558.3118 | Val 59633.2129\n",
            "VAE Epoch: 2420/8500 \tLoss: 60558.3118 \tRecon Loss: 56950.3066 \tKL Div: 38.0182\n",
            "[VAE] Ep 2430/8500 Train 60524.2637 | Val 59759.6426\n",
            "VAE Epoch: 2430/8500 \tLoss: 60524.2637 \tRecon Loss: 56925.8477 \tKL Div: 37.7612\n",
            "   ↪︎ New best val loss 59539.8398  (checkpoint)\n",
            "[VAE] Ep 2440/8500 Train 60765.1556 | Val 59686.2754\n",
            "VAE Epoch: 2440/8500 \tLoss: 60765.1556 \tRecon Loss: 57102.6934 \tKL Div: 38.2757\n",
            "   ↪︎ New best val loss 59513.0020  (checkpoint)\n",
            "[VAE] Ep 2450/8500 Train 60541.3099 | Val 59520.0488\n",
            "VAE Epoch: 2450/8500 \tLoss: 60541.3099 \tRecon Loss: 56900.7839 \tKL Div: 37.8912\n",
            "[VAE] Ep 2460/8500 Train 61105.9512 | Val 60337.4219\n",
            "VAE Epoch: 2460/8500 \tLoss: 61105.9512 \tRecon Loss: 57432.6074 \tKL Div: 38.0773\n",
            "[VAE] Ep 2470/8500 Train 60797.9460 | Val 59652.2871\n",
            "VAE Epoch: 2470/8500 \tLoss: 60797.9460 \tRecon Loss: 57103.5332 \tKL Div: 38.1407\n",
            "[VAE] Ep 2480/8500 Train 60463.0176 | Val 59731.6504\n",
            "VAE Epoch: 2480/8500 \tLoss: 60463.0176 \tRecon Loss: 56759.0137 \tKL Div: 38.0855\n",
            "   ↪︎ New best val loss 59488.7852  (checkpoint)\n",
            "[VAE] Ep 2490/8500 Train 60526.8841 | Val 59589.1797\n",
            "VAE Epoch: 2490/8500 \tLoss: 60526.8841 \tRecon Loss: 56845.7520 \tKL Div: 37.6983\n",
            "   ↪︎ New best val loss 59482.0430  (checkpoint)\n",
            "[VAE] Ep 2500/8500 Train 60637.0801 | Val 59596.2012\n",
            "VAE Epoch: 2500/8500 \tLoss: 60637.0801 \tRecon Loss: 56911.4753 \tKL Div: 38.0012\n",
            "   ↪︎ New best val loss 59456.0293  (checkpoint)\n",
            "   ↪︎ New best val loss 59428.1113  (checkpoint)\n",
            "   ↪︎ New best val loss 59414.7227  (checkpoint)\n",
            "[VAE] Ep 2510/8500 Train 60568.3516 | Val 59541.1758\n",
            "VAE Epoch: 2510/8500 \tLoss: 60568.3516 \tRecon Loss: 56848.3828 \tKL Div: 37.7925\n",
            "[VAE] Ep 2520/8500 Train 60814.1198 | Val 59537.3867\n",
            "VAE Epoch: 2520/8500 \tLoss: 60814.1198 \tRecon Loss: 57116.3040 \tKL Div: 37.4184\n",
            "[VAE] Ep 2530/8500 Train 60640.7311 | Val 59478.7227\n",
            "VAE Epoch: 2530/8500 \tLoss: 60640.7311 \tRecon Loss: 56898.0013 \tKL Div: 37.7232\n",
            "[VAE] Ep 2540/8500 Train 60751.4954 | Val 59577.4609\n",
            "VAE Epoch: 2540/8500 \tLoss: 60751.4954 \tRecon Loss: 56997.3086 \tKL Div: 37.6897\n",
            "   ↪︎ New best val loss 59340.8535  (checkpoint)\n",
            "[VAE] Ep 2550/8500 Train 60739.9896 | Val 59502.8828\n",
            "VAE Epoch: 2550/8500 \tLoss: 60739.9896 \tRecon Loss: 56981.4889 \tKL Div: 37.5850\n",
            "[VAE] Ep 2560/8500 Train 60900.5137 | Val 59723.0684\n",
            "VAE Epoch: 2560/8500 \tLoss: 60900.5137 \tRecon Loss: 57182.9909 \tKL Div: 37.1752\n",
            "[VAE] Ep 2570/8500 Train 60693.1374 | Val 59531.7910\n",
            "VAE Epoch: 2570/8500 \tLoss: 60693.1374 \tRecon Loss: 56912.9993 \tKL Div: 37.8014\n",
            "[VAE] Ep 2580/8500 Train 60700.8314 | Val 59771.7109\n",
            "VAE Epoch: 2580/8500 \tLoss: 60700.8314 \tRecon Loss: 56939.9492 \tKL Div: 37.6088\n",
            "[VAE] Ep 2590/8500 Train 60672.1237 | Val 59492.9688\n",
            "VAE Epoch: 2590/8500 \tLoss: 60672.1237 \tRecon Loss: 56928.0436 \tKL Div: 37.4408\n",
            "[VAE] Ep 2600/8500 Train 60843.8984 | Val 59843.9219\n",
            "VAE Epoch: 2600/8500 \tLoss: 60843.8984 \tRecon Loss: 57078.8587 \tKL Div: 37.6504\n",
            "   ↪︎ New best val loss 59304.3945  (checkpoint)\n",
            "[VAE] Ep 2610/8500 Train 60576.4460 | Val 59477.7715\n",
            "VAE Epoch: 2610/8500 \tLoss: 60576.4460 \tRecon Loss: 56813.7370 \tKL Div: 37.6271\n",
            "   ↪︎ New best val loss 59299.4844  (checkpoint)\n",
            "[VAE] Ep 2620/8500 Train 60916.0872 | Val 59724.9375\n",
            "VAE Epoch: 2620/8500 \tLoss: 60916.0872 \tRecon Loss: 57128.0911 \tKL Div: 37.8800\n",
            "[VAE] Ep 2630/8500 Train 60624.8359 | Val 59367.5312\n",
            "VAE Epoch: 2630/8500 \tLoss: 60624.8359 \tRecon Loss: 56894.3919 \tKL Div: 37.3044\n",
            "[VAE] Ep 2640/8500 Train 60457.1615 | Val 59509.8945\n",
            "VAE Epoch: 2640/8500 \tLoss: 60457.1615 \tRecon Loss: 56693.4746 \tKL Div: 37.6369\n",
            "[VAE] Ep 2650/8500 Train 60630.1367 | Val 59527.9473\n",
            "VAE Epoch: 2650/8500 \tLoss: 60630.1367 \tRecon Loss: 56816.7142 \tKL Div: 38.1342\n",
            "   ↪︎ New best val loss 59296.5957  (checkpoint)\n",
            "[VAE] Ep 2660/8500 Train 60500.7383 | Val 59480.4336\n",
            "VAE Epoch: 2660/8500 \tLoss: 60500.7383 \tRecon Loss: 56659.5247 \tKL Div: 38.4121\n",
            "   ↪︎ New best val loss 59250.7891  (checkpoint)\n",
            "[VAE] Ep 2670/8500 Train 60459.6439 | Val 59505.3047\n",
            "VAE Epoch: 2670/8500 \tLoss: 60459.6439 \tRecon Loss: 56696.2044 \tKL Div: 37.6344\n",
            "[VAE] Ep 2680/8500 Train 60832.3594 | Val 59675.0645\n",
            "VAE Epoch: 2680/8500 \tLoss: 60832.3594 \tRecon Loss: 57049.3268 \tKL Div: 37.8303\n",
            "[VAE] Ep 2690/8500 Train 60423.8040 | Val 59337.2559\n",
            "VAE Epoch: 2690/8500 \tLoss: 60423.8040 \tRecon Loss: 56637.6536 \tKL Div: 37.8615\n",
            "[VAE] Ep 2700/8500 Train 60638.8542 | Val 59376.5879\n",
            "VAE Epoch: 2700/8500 \tLoss: 60638.8542 \tRecon Loss: 56877.4089 \tKL Div: 37.6144\n",
            "[VAE] Ep 2710/8500 Train 60522.8997 | Val 59518.9023\n",
            "VAE Epoch: 2710/8500 \tLoss: 60522.8997 \tRecon Loss: 56711.1263 \tKL Div: 38.1177\n",
            "[VAE] Ep 2720/8500 Train 60560.4805 | Val 59659.9258\n",
            "VAE Epoch: 2720/8500 \tLoss: 60560.4805 \tRecon Loss: 56829.2461 \tKL Div: 37.3124\n",
            "[VAE] Ep 2730/8500 Train 60358.9408 | Val 59240.3516\n",
            "   ↪︎ New best val loss 59240.3516  (checkpoint)\n",
            "VAE Epoch: 2730/8500 \tLoss: 60358.9408 \tRecon Loss: 56628.3249 \tKL Div: 37.3062\n",
            "[VAE] Ep 2740/8500 Train 60378.5605 | Val 59266.3906\n",
            "VAE Epoch: 2740/8500 \tLoss: 60378.5605 \tRecon Loss: 56563.1934 \tKL Div: 38.1537\n",
            "[VAE] Ep 2750/8500 Train 60455.4707 | Val 59250.7891\n",
            "VAE Epoch: 2750/8500 \tLoss: 60455.4707 \tRecon Loss: 56684.6178 \tKL Div: 37.7085\n",
            "   ↪︎ New best val loss 59237.5098  (checkpoint)\n",
            "[VAE] Ep 2760/8500 Train 60220.2767 | Val 59342.9238\n",
            "VAE Epoch: 2760/8500 \tLoss: 60220.2767 \tRecon Loss: 56423.7917 \tKL Div: 37.9649\n",
            "   ↪︎ New best val loss 59222.0215  (checkpoint)\n",
            "[VAE] Ep 2770/8500 Train 60371.7539 | Val 59397.7109\n",
            "VAE Epoch: 2770/8500 \tLoss: 60371.7539 \tRecon Loss: 56606.8783 \tKL Div: 37.6488\n",
            "   ↪︎ New best val loss 59181.9258  (checkpoint)\n",
            "   ↪︎ New best val loss 59068.6133  (checkpoint)\n",
            "[VAE] Ep 2780/8500 Train 60281.5599 | Val 59227.7676\n",
            "VAE Epoch: 2780/8500 \tLoss: 60281.5599 \tRecon Loss: 56495.2272 \tKL Div: 37.8633\n",
            "[VAE] Ep 2790/8500 Train 60478.6413 | Val 59336.6250\n",
            "VAE Epoch: 2790/8500 \tLoss: 60478.6413 \tRecon Loss: 56678.8470 \tKL Div: 37.9979\n",
            "[VAE] Ep 2800/8500 Train 60396.1875 | Val 59344.6641\n",
            "VAE Epoch: 2800/8500 \tLoss: 60396.1875 \tRecon Loss: 56618.0710 \tKL Div: 37.7812\n",
            "[VAE] Ep 2810/8500 Train 60248.3184 | Val 59249.3926\n",
            "VAE Epoch: 2810/8500 \tLoss: 60248.3184 \tRecon Loss: 56454.6270 \tKL Div: 37.9369\n",
            "   ↪︎ New best val loss 59056.6016  (checkpoint)\n",
            "[VAE] Ep 2820/8500 Train 60469.7337 | Val 59329.4023\n",
            "VAE Epoch: 2820/8500 \tLoss: 60469.7337 \tRecon Loss: 56676.3516 \tKL Div: 37.9338\n",
            "[VAE] Ep 2830/8500 Train 60452.5859 | Val 59311.4941\n",
            "VAE Epoch: 2830/8500 \tLoss: 60452.5859 \tRecon Loss: 56670.1517 \tKL Div: 37.8243\n",
            "[VAE] Ep 2840/8500 Train 60496.1230 | Val 59548.2852\n",
            "VAE Epoch: 2840/8500 \tLoss: 60496.1230 \tRecon Loss: 56721.6094 \tKL Div: 37.7451\n",
            "[VAE] Ep 2850/8500 Train 60549.7031 | Val 59310.9473\n",
            "VAE Epoch: 2850/8500 \tLoss: 60549.7031 \tRecon Loss: 56775.2565 \tKL Div: 37.7445\n",
            "[VAE] Ep 2860/8500 Train 60316.5020 | Val 59159.2363\n",
            "VAE Epoch: 2860/8500 \tLoss: 60316.5020 \tRecon Loss: 56554.5846 \tKL Div: 37.6192\n",
            "   ↪︎ New best val loss 59050.8320  (checkpoint)\n",
            "[VAE] Ep 2870/8500 Train 60365.4382 | Val 59592.8711\n",
            "VAE Epoch: 2870/8500 \tLoss: 60365.4382 \tRecon Loss: 56600.4499 \tKL Div: 37.6499\n",
            "   ↪︎ New best val loss 58948.5762  (checkpoint)\n",
            "[VAE] Ep 2880/8500 Train 60164.8490 | Val 59042.6914\n",
            "VAE Epoch: 2880/8500 \tLoss: 60164.8490 \tRecon Loss: 56390.4290 \tKL Div: 37.7442\n",
            "[VAE] Ep 2890/8500 Train 60108.7051 | Val 59297.5527\n",
            "VAE Epoch: 2890/8500 \tLoss: 60108.7051 \tRecon Loss: 56330.2650 \tKL Div: 37.7844\n",
            "[VAE] Ep 2900/8500 Train 60322.1413 | Val 59069.3848\n",
            "VAE Epoch: 2900/8500 \tLoss: 60322.1413 \tRecon Loss: 56528.4271 \tKL Div: 37.9371\n",
            "[VAE] Ep 2910/8500 Train 60326.0182 | Val 59113.4336\n",
            "VAE Epoch: 2910/8500 \tLoss: 60326.0182 \tRecon Loss: 56544.2897 \tKL Div: 37.8173\n",
            "[VAE] Ep 2920/8500 Train 60152.6504 | Val 59092.9473\n",
            "VAE Epoch: 2920/8500 \tLoss: 60152.6504 \tRecon Loss: 56331.2122 \tKL Div: 38.2144\n",
            "[VAE] Ep 2930/8500 Train 60262.5456 | Val 59016.8496\n",
            "VAE Epoch: 2930/8500 \tLoss: 60262.5456 \tRecon Loss: 56454.7663 \tKL Div: 38.0778\n",
            "   ↪︎ New best val loss 58827.4082  (checkpoint)\n",
            "[VAE] Ep 2940/8500 Train 60344.3424 | Val 59121.4355\n",
            "VAE Epoch: 2940/8500 \tLoss: 60344.3424 \tRecon Loss: 56536.8483 \tKL Div: 38.0749\n",
            "[VAE] Ep 2950/8500 Train 60376.4323 | Val 59382.2578\n",
            "VAE Epoch: 2950/8500 \tLoss: 60376.4323 \tRecon Loss: 56642.5013 \tKL Div: 37.3393\n",
            "[VAE] Ep 2960/8500 Train 60428.4714 | Val 59197.6816\n",
            "VAE Epoch: 2960/8500 \tLoss: 60428.4714 \tRecon Loss: 56634.0781 \tKL Div: 37.9439\n",
            "[VAE] Ep 2970/8500 Train 60176.4538 | Val 59200.1621\n",
            "VAE Epoch: 2970/8500 \tLoss: 60176.4538 \tRecon Loss: 56381.7116 \tKL Div: 37.9474\n",
            "[VAE] Ep 2980/8500 Train 60359.2051 | Val 58877.0039\n",
            "VAE Epoch: 2980/8500 \tLoss: 60359.2051 \tRecon Loss: 56560.0312 \tKL Div: 37.9917\n",
            "[VAE] Ep 2990/8500 Train 60343.7904 | Val 59098.3242\n",
            "VAE Epoch: 2990/8500 \tLoss: 60343.7904 \tRecon Loss: 56570.4993 \tKL Div: 37.7329\n",
            "[VAE] Ep 3000/8500 Train 60161.6803 | Val 59098.3418\n",
            "VAE Epoch: 3000/8500 \tLoss: 60161.6803 \tRecon Loss: 56354.6237 \tKL Div: 38.0706\n",
            "   ↪︎ New best val loss 58798.3066  (checkpoint)\n",
            "[VAE] Ep 3010/8500 Train 60297.7786 | Val 59067.9766\n",
            "VAE Epoch: 3010/8500 \tLoss: 60297.7786 \tRecon Loss: 56503.9798 \tKL Div: 37.9380\n",
            "[VAE] Ep 3020/8500 Train 60304.1283 | Val 58826.8535\n",
            "VAE Epoch: 3020/8500 \tLoss: 60304.1283 \tRecon Loss: 56502.9805 \tKL Div: 38.0115\n",
            "[VAE] Ep 3030/8500 Train 60010.8379 | Val 58985.7109\n",
            "VAE Epoch: 3030/8500 \tLoss: 60010.8379 \tRecon Loss: 56233.4141 \tKL Div: 37.7742\n",
            "[VAE] Ep 3040/8500 Train 60140.5697 | Val 58914.3262\n",
            "VAE Epoch: 3040/8500 \tLoss: 60140.5697 \tRecon Loss: 56335.4154 \tKL Div: 38.0515\n",
            "[VAE] Ep 3050/8500 Train 60201.2122 | Val 59015.7930\n",
            "VAE Epoch: 3050/8500 \tLoss: 60201.2122 \tRecon Loss: 56429.5384 \tKL Div: 37.7167\n",
            "[VAE] Ep 3060/8500 Train 60173.2389 | Val 58988.5742\n",
            "VAE Epoch: 3060/8500 \tLoss: 60173.2389 \tRecon Loss: 56358.9759 \tKL Div: 38.1426\n",
            "[VAE] Ep 3070/8500 Train 60160.3086 | Val 59044.0879\n",
            "VAE Epoch: 3070/8500 \tLoss: 60160.3086 \tRecon Loss: 56368.3568 \tKL Div: 37.9195\n",
            "[VAE] Ep 3080/8500 Train 60302.0176 | Val 58931.3730\n",
            "VAE Epoch: 3080/8500 \tLoss: 60302.0176 \tRecon Loss: 56514.5312 \tKL Div: 37.8749\n",
            "[VAE] Ep 3090/8500 Train 60137.8815 | Val 59154.4668\n",
            "VAE Epoch: 3090/8500 \tLoss: 60137.8815 \tRecon Loss: 56278.6628 \tKL Div: 38.5922\n",
            "[VAE] Ep 3100/8500 Train 60109.8216 | Val 59037.9004\n",
            "VAE Epoch: 3100/8500 \tLoss: 60109.8216 \tRecon Loss: 56297.6491 \tKL Div: 38.1217\n",
            "   🛑 Early-stopping after 100 epochs w/o improvement.\n",
            "--- VAE Training Finished ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-3d2085c2bd34>:442: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  vae.load_state_dict(torch.load(os.path.join(PROJECT_DIR, f\"beta_vae_fold{FOLD_NUMBER}.pt\")))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AD/CN Train/Val data shape: torch.Size([145, 4, 166, 166])\n",
            "AD/CN Test data shape: torch.Size([38, 4, 166, 166])\n",
            "Saved average saliency map visualization to /content/drive/MyDrive/GrandMeanNorm/\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Analysis Complete ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(vae.encoder.state_dict(), \"encoder_best.pt\")\n"
      ],
      "metadata": {
        "id": "Pqn7suIuuql2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %% ─────────── Clasificación AD vs CN  (μ  vs  μ+σ) ───────────\n",
        "\"\"\"\n",
        "Requiere en memoria: vae, DEVICE, clf_train_data, test_ad_cn_data,\n",
        "clf_train_labels, test_ad_cn_labels_bin, PROJECT_DIR, FOLD_NUMBER, SEED\n",
        "\"\"\"\n",
        "\n",
        "import os, pickle, warnings, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
        "import seaborn as sns, lightgbm as lgb, torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing   import RobustScaler\n",
        "from sklearn.decomposition   import PCA\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
        "from sklearn.metrics         import (accuracy_score, precision_score, recall_score,\n",
        "                                     f1_score, roc_auc_score, roc_curve)\n",
        "from sklearn.linear_model    import LogisticRegression\n",
        "from sklearn.svm             import SVC\n",
        "from sklearn.ensemble        import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.neural_network  import MLPClassifier\n",
        "from sklearn.base            import clone\n",
        "\n",
        "# ─────────────────── ajustes visuales / warnings ───────────────────\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams[\"figure.dpi\"] = 110\n",
        "#lgb.basic._config.set({\"verbosity\": -1})      # silencia LightGBM\n",
        "\n",
        "# ───────────────────────── helpers ─────────────────────────\n",
        "def encode_latents(encoder, tensors, use_sigma=False, batch=128):\n",
        "    \"\"\"Devuelve array (N, latent_dim [×2]) con μ o μ+σ.\"\"\"\n",
        "    dl, outs = DataLoader(TensorDataset(tensors),\n",
        "                          batch_size=batch, pin_memory=True), []\n",
        "    encoder.eval()\n",
        "    with torch.no_grad():\n",
        "        for (x,) in dl:\n",
        "            mu, logvar = encoder(x.to(DEVICE))\n",
        "            z = torch.cat([mu, torch.exp(0.5*logvar)], 1) if use_sigma else mu\n",
        "            outs.append(z.cpu().numpy())\n",
        "    return np.vstack(outs)\n",
        "\n",
        "def youden_threshold(y_true, y_prob):\n",
        "    fpr, tpr, thr = roc_curve(y_true, y_prob)\n",
        "    return thr[np.argmax(tpr - fpr)]\n",
        "\n",
        "def run_variant(tag:str, use_sigma:bool=False):\n",
        "    # 1) Latentes\n",
        "    Z_tr = encode_latents(vae.encoder, clf_train_data, use_sigma)\n",
        "    Z_te = encode_latents(vae.encoder, test_ad_cn_data, use_sigma)\n",
        "\n",
        "    # 2) RobustScaler + PCA (95 % var)\n",
        "    scaler = RobustScaler()\n",
        "    Z_tr   = scaler.fit_transform(Z_tr);  Z_te = scaler.transform(Z_te)\n",
        "    pca    = PCA(0.95, random_state=SEED)\n",
        "    Z_tr   = pca.fit_transform(Z_tr);     Z_te = pca.transform(Z_te)\n",
        "    n_dim  = Z_tr.shape[1]\n",
        "\n",
        "    # 3) Modelos y grids\n",
        "    base = {\n",
        "        \"LogReg\": LogisticRegression(max_iter=2000, class_weight=\"balanced\"),\n",
        "        \"SVM\":    SVC(kernel=\"linear\", probability=True, class_weight=\"balanced\"),\n",
        "        \"RF\":     RandomForestClassifier(n_estimators=400, class_weight=\"balanced\",\n",
        "                                         random_state=SEED),\n",
        "        \"GB\":     GradientBoostingClassifier(n_estimators=300, random_state=SEED),\n",
        "        \"LGBM\":   lgb.LGBMClassifier(objective=\"binary\", n_estimators=600,\n",
        "                                     learning_rate=0.05, subsample=.8,\n",
        "                                     colsample_bytree=.8, class_weight=\"balanced\",\n",
        "                                     random_state=SEED, verbosity=-1),\n",
        "        \"MLP\":    MLPClassifier(max_iter=800, random_state=SEED)\n",
        "    }\n",
        "    grids = {\n",
        "        \"LogReg\": {'C':[.01,.1,1,10]},\n",
        "        \"SVM\":    {'C':[.01,.1,1,10]},\n",
        "        \"RF\":     {'max_depth':[None,5,10]},\n",
        "        \"GB\":     {'learning_rate':[.01,.05,.1],'max_depth':[3,5]},\n",
        "        \"LGBM\":   {'num_leaves':[31,63], 'reg_lambda':[0.,1.]},\n",
        "        \"MLP\":    {'hidden_layer_sizes':[(100,),(150,),(100,50)],\n",
        "                   'alpha':[1e-5,1e-4,1e-3]}\n",
        "    }\n",
        "\n",
        "    inner   = StratifiedKFold(3, shuffle=True, random_state=SEED)\n",
        "    y_tr    = clf_train_labels.numpy()\n",
        "    y_te    = test_ad_cn_labels_bin\n",
        "    metrics, best_params, best_models, roc_probs = {}, {}, {}, {}\n",
        "\n",
        "    for name, model in base.items():\n",
        "        gs = GridSearchCV(model, grids[name], cv=inner,\n",
        "                          scoring=\"roc_auc\", n_jobs=-1)\n",
        "        gs.fit(Z_tr, y_tr)\n",
        "        best_params[name] = gs.best_params_\n",
        "        best_models[name] = gs.best_estimator_        # ya entrenado en cv\n",
        "\n",
        "        y_prob = best_models[name].predict_proba(Z_te)[:,1]\n",
        "        thr    = youden_threshold(y_te, y_prob)\n",
        "        y_pred = (y_prob >= thr).astype(int)\n",
        "\n",
        "        metrics[name] = dict(Variant=tag, Accuracy=accuracy_score(y_te, y_pred),\n",
        "                             Precision=precision_score(y_te, y_pred, zero_division=0),\n",
        "                             Recall=recall_score(y_te, y_pred, zero_division=0),\n",
        "                             F1=f1_score(y_te, y_pred, zero_division=0),\n",
        "                             AUC=roc_auc_score(y_te, y_prob), Thr=thr, Dim=n_dim)\n",
        "        roc_probs[name] = y_prob\n",
        "\n",
        "    # 4) Curva ROC combinada\n",
        "    plt.figure()\n",
        "    for n, prob in roc_probs.items():\n",
        "        fpr,tpr,_ = roc_curve(y_te, prob)\n",
        "        plt.plot(fpr,tpr,lw=1.8,label=f\"{n} (AUC {metrics[n]['AUC']:.2f})\")\n",
        "    plt.plot([0,1],[0,1],'k--'); plt.title(f\"ROC – {tag}\")\n",
        "    plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.legend(); plt.tight_layout(); plt.show()\n",
        "\n",
        "    # 5) guardar mejor modelo (según AUC) re-entrenado con todo el train\n",
        "    best_name = max(metrics, key=lambda k: metrics[k][\"AUC\"])\n",
        "    final_est = clone(base[best_name]).set_params(**best_params[best_name])\n",
        "    final_est.fit(Z_tr, y_tr)\n",
        "    fname = os.path.join(PROJECT_DIR, f\"best_{tag}_fold{FOLD_NUMBER}.pkl\")\n",
        "    with open(fname, \"wb\") as f: pickle.dump(final_est, f)\n",
        "\n",
        "    print(f\"✅ {tag}: mejor {best_name}  AUC={metrics[best_name]['AUC']:.3f}  → {fname}\")\n",
        "    return metrics\n",
        "\n",
        "\n",
        "\n",
        "# ───────────────────── correr ambas variantes ─────────────────────\n",
        "metrics_mu       = run_variant(\"mu\",       use_sigma=False)\n",
        "metrics_mu_sigma = run_variant(\"mu_sigma\", use_sigma=True)\n",
        "\n",
        "# ───────────────────── resumen en tabla ─────────────────────\n",
        "def to_df(mdict): return pd.DataFrame(mdict).T.reset_index().rename(columns={'index':'Model'})\n",
        "summary = pd.concat([\n",
        "    to_df(metrics_mu),\n",
        "    to_df(metrics_mu_sigma)\n",
        "], ignore_index=True)\n",
        "\n",
        "print(\"\\nResumen comparativo (↑ mejor):\")\n",
        "print(summary.round(3).to_string(index=False))  # <- muestra todo en consola\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "avhj9bGqwDvL",
        "outputId": "548a2cfd-9232-498b-ef5d-422ca9e1895a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 704x528 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ mu: mejor SVM  AUC=0.845  → /content/drive/MyDrive/GrandMeanNorm/best_mu_fold1.pkl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 704x528 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ mu_sigma: mejor LogReg  AUC=0.823  → /content/drive/MyDrive/GrandMeanNorm/best_mu_sigma_fold1.pkl\n",
            "\n",
            "Resumen comparativo (↑ mejor):\n",
            " Model  Variant  Accuracy Precision    Recall        F1       AUC       Thr Dim\n",
            "LogReg       mu  0.789474  0.823529  0.736842  0.777778  0.833795  0.628641  24\n",
            "   SVM       mu  0.815789       0.8  0.842105  0.820513  0.844875  0.507423  24\n",
            "    RF       mu  0.710526  0.785714  0.578947  0.666667  0.752078     0.615  24\n",
            "    GB       mu  0.684211  0.733333  0.578947  0.647059  0.648199  0.740412  24\n",
            "  LGBM       mu  0.684211  0.684211  0.684211  0.684211  0.623269  0.653279  24\n",
            "   MLP       mu  0.789474  0.866667  0.684211  0.764706  0.806094  0.929644  24\n",
            "LogReg mu_sigma  0.815789  0.833333  0.789474  0.810811  0.822715   0.52112  28\n",
            "   SVM mu_sigma  0.736842  0.764706  0.684211  0.722222  0.774238  0.532566  28\n",
            "    RF mu_sigma  0.763158  0.916667  0.578947  0.709677  0.714681  0.572973  28\n",
            "    GB mu_sigma  0.710526  0.785714  0.578947  0.666667   0.66482  0.807328  28\n",
            "  LGBM mu_sigma  0.684211      0.64  0.842105  0.727273   0.66482  0.262747  28\n",
            "   MLP mu_sigma  0.789474  0.761905  0.842105       0.8  0.808864  0.503306  28\n"
          ]
        }
      ]
    }
  ]
}